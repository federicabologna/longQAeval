{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.getcwd()\n",
    "data_dir = os.path.join(dir, 'data')\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "output_dir = os.path.join(dir, 'output')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(os.path.join(data_dir, 'kqa_golden_test_MedLFQA.jsonl'), 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.strip()))\n",
    "\n",
    "output_path = os.path.join(output_dir,  f'kqa-questions.jsonl')\n",
    "\n",
    "id = 1\n",
    "\n",
    "for d in data:\n",
    "\n",
    "    d['id'] = id\n",
    "\n",
    "    with open(output_path, 'a') as file:\n",
    "        json.dump(d, file)\n",
    "        file.write('\\n') \n",
    "    \n",
    "    id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(output_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.strip()))\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 5 and 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(os.path.join(data_dir, 'kqa_qa_pairs.jsonl'), 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "random_state = 23\n",
    "\n",
    "# Draw five examples at random\n",
    "random.seed(random_state)\n",
    "indexes_5 = random.sample(range(len(data)), 5)\n",
    "sample_5 = [data[i] for i in indexes_5]\n",
    "print(sample_5[3])\n",
    "\n",
    "# Remove the sampled 5 dictionaries for few-shot from the original list\n",
    "for idx in indexes_5:\n",
    "    data.pop(idx)\n",
    "print(len(data))\n",
    "\n",
    "# Step 2: Sample 100 dictionaries at random from the remaining data\n",
    "random.seed(random_state)\n",
    "sample_100 = random.sample(data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in sample_5:    \n",
    "    with open(os.path.join(data_dir, 'sample_5.jsonl'), 'a') as file:\n",
    "        json.dump(d, file)\n",
    "        file.write('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in sample_100:    \n",
    "    with open(os.path.join(data_dir, 'sample_100.jsonl'), 'a') as file:\n",
    "        json.dump(d, file)\n",
    "        file.write('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get examples\n",
    "sample_5 = []\n",
    "with open(os.path.join(data_dir, 'sample_5.jsonl'), 'r') as f:\n",
    "    for line in f:\n",
    "        sample_5.append(json.loads(line.strip()))\n",
    "print(sample_5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f'''You are a trained physician. Answer this question from a fellow clinician by providing correct, relevant, and safe information. Make sure to keep your answer under 270 words and do not hedge. Follow these steps:\n",
    "\n",
    "Read the question.\n",
    "Respond with medical information that is correct, relevant, and safe given the question asked.\n",
    "Formulate your answer in less than 270 words and do not hedge!\n",
    "\n",
    "Here are five example of correct, relevant, and safe answers to clinical questions:\n",
    "\n",
    "Example 1:\n",
    "Question: {sample_5[0]['Question']}\n",
    "Answer: {sample_5[0]['Free_form_answer']}\n",
    "\n",
    "Example 2:\n",
    "Question: {sample_5[1]['Question']}\n",
    "Answer: {sample_5[1]['Free_form_answer']}\n",
    "\n",
    "Example 3:\n",
    "Question: {sample_5[2]['Question']}\n",
    "Answer: {sample_5[2]['Free_form_answer']}\n",
    "\n",
    "Example 4:\n",
    "Question: {sample_5[3]['Question']}\n",
    "Answer: {sample_5[3]['Free_form_answer']}\n",
    "\n",
    "Example 5:\n",
    "Question: {sample_5[4]['Question']}\n",
    "Answer: {sample_5[4]['Free_form_answer']}\n",
    "\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "with open(os.path.join(data_dir, 'five_shot_prompt.txt'), \"w\") as file:\n",
    "    file.write(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From JSONL to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, \"kqa_answers_gpt4_five.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    data = [json.loads(line) for line in jsonl_file]\n",
    "\n",
    "lower_data = [{k.lower(): v for k, v in record.items()} for record in data]\n",
    "\n",
    "selected_fields = ['id', 'question', 'answer']\n",
    "\n",
    "filtered_data = [{field: record.get(field, None) for field in selected_fields} for record in data]\n",
    "\n",
    "with open(os.path.join(output_dir, \"kqa_answers_gpt4_five.csv\"), 'w', encoding='utf-8', newline='') as csv_file:\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=selected_fields)\n",
    "    \n",
    "    # Write header\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Write rows\n",
    "    writer.writerows(filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create separate answer files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, \"kqa_answers_gpt4_five.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    data = [json.loads(line) for line in jsonl_file]\n",
    "\n",
    "for answer_type in ['gpt4', 'physician']:\n",
    "    \n",
    "    answer_n = 0\n",
    "    \n",
    "    for d in data:\n",
    "        \n",
    "        answer_id = f'{answer_type}_{answer_n}'\n",
    "        \n",
    "        if answer_type == 'gpt4':\n",
    "            answer = d['answer']    \n",
    "        elif answer_type == 'physician':\n",
    "            answer = d['Free_form_answer']\n",
    "        question_number = d['id']\n",
    "        \n",
    "        new_d = {'question_id': f'question_{question_number}',\n",
    "                'question': d['Question'],\n",
    "                'answer_id': answer_id,\n",
    "                'answer': answer,\n",
    "                'answer_type': answer_type}\n",
    "        \n",
    "        with open(os.path.join(output_dir, f'{answer_type}_answers.jsonl'), 'a') as file:\n",
    "            json.dump(new_d, file)\n",
    "            file.write('\\n')\n",
    "        \n",
    "        answer_n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(output_dir, \"kqa_answers_llama_five.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    data = [json.loads(line) for line in jsonl_file]\n",
    "    \n",
    "answer_n = 0\n",
    "\n",
    "for d in data:\n",
    "    \n",
    "    answer_id = f'llama_{answer_n}'\n",
    "    \n",
    "    answer = d['answer']\n",
    "    question_number = d['id']\n",
    "    \n",
    "    new_d = {'question_id': f'question_{question_number}',\n",
    "            'question': d['Question'],\n",
    "            'answer_id': answer_id,\n",
    "            'answer': answer,\n",
    "            'answer_type': 'llama'}\n",
    "    \n",
    "    with open(os.path.join(output_dir, f'llama_answers.jsonl'), 'a') as file:\n",
    "        json.dump(new_d, file)\n",
    "        file.write('\\n')\n",
    "    \n",
    "    answer_n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From JSON to annotator files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(17)\n",
    "\n",
    "for annotator, assignments in annotators.items():\n",
    "    \n",
    "    while len(assignments) < 50:\n",
    "        sample = random.sample(physicians, 3)[0]\n",
    "        if sample['id'] not in assignments and annotator not in sample['annotators'] and len(sample['annotators']) < 4:\n",
    "            assignments.append(sample['id'])\n",
    "            sample['annotators'].append(annotator)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pilot files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"kqa_qa_pairs.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    og = [json.loads(line) for line in jsonl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"sample_5.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    fiveshot = [json.loads(line) for line in jsonl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_dir, \"sample_100.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    annotations = [json.loads(line) for line in jsonl_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "used_ids = [d['id'] for d in annotations] + [d['id'] for d in fiveshot]\n",
    "len((set(used_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Question': 'What is a neurological issue', 'Free_form_answer': \"A neurological issue is a problem that affects the nervous system, which includes the brain, spinal cord, and peripheral nerves. The nervous system is in charge of many of our human abilities, such as our ability to speak, move, and think. Neurological issues are conditions where those abilities are impaired. Among the common neurological issues are stroke, epilepsy, Multiple sclerosis, Alzheimer's disease, and Peripheral neuropathy. \", 'Must_have': ['A neurological issue is a problem that affects the nervous system.', ' Neurological issues are conditions where abilities such as speaking, moving, thinking are impaired.'], 'Nice_to_have': ['Epilepsy is a neurological issue.', ' Stroke is a neurological issue.', \" Alzheimer's disease is a neurological issue.\", ' Peripheral neuropathy is a neurological issue.', ' The nervous system is in charge of human abilities such as the ability to speak, move, think.', ' The nervous system includes the brain, spinal cord, and peripheral nerves.', ' Multiple sclerosis is a neurological issue.'], 'id': 164}\n"
     ]
    }
   ],
   "source": [
    "pool = [d for d in og if d['id'] not in used_ids]\n",
    "\n",
    "# Set random seed\n",
    "random_state = 23\n",
    "\n",
    "# Draw five examples at random\n",
    "random.seed(random_state)\n",
    "pilot_sample = random.sample(pool, 18)\n",
    "print(pilot_sample[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = used_ids + [d['id'] for d in pilot_sample]\n",
    "len(set(check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in pilot_sample:    \n",
    "    with open(os.path.join(data_dir, 'pilot_sample.jsonl'), 'a') as file:\n",
    "        json.dump(d, file)\n",
    "        file.write('\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, \":orange[This is the first sentence.] Here's the second one! Is this the third sentence? Yes, it is.\")\n",
      "(1, \"This is the first sentence. :orange[Here's the second one!] Is this the third sentence? Yes, it is.\")\n",
      "(2, \"This is the first sentence. Here's the second one! :orange[Is this the third sentence?] Yes, it is.\")\n",
      "(3, \"This is the first sentence. Here's the second one! Is this the third sentence? :orange[Yes, it is.]\")\n"
     ]
    }
   ],
   "source": [
    "def bold_sentences(text):\n",
    "    \n",
    "    # Load the spaCy English model\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # Process the text with spaCy to segment into sentences\n",
    "    doc = nlp(text)\n",
    "    sentences = [sentence.text for sentence in doc.sents]\n",
    "    fine_sentences = []\n",
    "    for bold_index in range(len(sentences)):\n",
    "        bold_sentence = f':orange[{sentences[bold_index]}]'\n",
    "        new_sentences = sentences[:bold_index] + [bold_sentence] + sentences[bold_index + 1:]\n",
    "        fine_sentence = ' '.join(new_sentences)\n",
    "        fine_sentences.append((bold_index, fine_sentence))\n",
    "    \n",
    "    return fine_sentences\n",
    "\n",
    "# Example text\n",
    "text = \"\"\"This is the first sentence. Here's the second one! Is this the third sentence? Yes, it is.\"\"\"\n",
    "\n",
    "# bold sentences in the example text\n",
    "for i in bold_sentences(text):\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(18):\n",
    "    \n",
    "    if n < 9:\n",
    "        annotation_type = 'coarse'\n",
    "    else:\n",
    "        annotation_type = 'fine'\n",
    "        \n",
    "    type_list = ['gpt4', 'llama', 'physician']\n",
    "    random.shuffle(type_list)\n",
    "    \n",
    "    for answer_type in type_list:\n",
    "        \n",
    "        if answer_type == 'physician':\n",
    "            with open(os.path.join(output_dir, \"pilot_gpt4_answers.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "                data = [json.loads(line) for line in jsonl_file]\n",
    "        else:\n",
    "            with open(os.path.join(output_dir, f\"pilot_{answer_type}_answers.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "                data = [json.loads(line) for line in jsonl_file]\n",
    "                    \n",
    "        d = data[n]\n",
    "        \n",
    "        if answer_type == 'physician':\n",
    "            answer = d['Free_form_answer']\n",
    "        else:\n",
    "            answer = d['answer']\n",
    "            \n",
    "        question_number = d['id']\n",
    "        \n",
    "        new_d = {'question_id': f'question_{question_number}',\n",
    "                 'question': d['Question'],\n",
    "                 'answer_id': f'{answer_type}_{n}',\n",
    "                 'answer_type': answer_type,\n",
    "                 'annotation_type': annotation_type,\n",
    "                 'rated': 'No'}\n",
    "        \n",
    "        if annotation_type == 'coarse':\n",
    "            \n",
    "            new_d['answer'] = answer\n",
    "\n",
    "            with open(os.path.join(output_dir, 'pilot_coarse.jsonl'), 'a') as file:\n",
    "                json.dump(new_d, file)\n",
    "                file.write('\\n')\n",
    "    \n",
    "        elif annotation_type == 'fine':\n",
    "            \n",
    "            sentences = bold_sentences(answer)\n",
    "            for sentence in sentences:\n",
    "                copy = new_d.copy()\n",
    "                copy['sentence_id'] = new_d['answer_id'] + f'_{sentence[0]}'\n",
    "                copy['answer'] = sentence[1]\n",
    "                \n",
    "                with open(os.path.join(output_dir, 'pilot_fine.jsonl'), 'a') as file:\n",
    "                    json.dump(copy, file)\n",
    "                    file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
