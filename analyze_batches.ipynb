{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import inter_rater as irr\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import krippendorff as kd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File locations\n",
    "dir = os.getcwd()\n",
    "output_dir = os.path.join(dir, 'output')\n",
    "fig_dir = os.path.join(dir, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO ASSEMBLE BATCHES\n",
    "# for n in range(1,7):\n",
    "#     if n not in [1,2,6]:\n",
    "#         results = []\n",
    "#         with open(os.path.join(output_dir, 'coarse', 'batches_1-9', f\"annotator{n}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "#             for line in jsonl_file:\n",
    "#                 d = json.loads(line)\n",
    "#                 d['annotator'] = f\"annotator{n}\"\n",
    "#                 results.append(d)\n",
    "        \n",
    "#         output_file = f\"annotator{n}.jsonl\"\n",
    "#         with open(os.path.join('output', 'coarse', output_file), 'w', encoding='utf-8') as f:\n",
    "#             for doc in results:\n",
    "#                 f.write(json.dumps(doc, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n in range(1,7):\n",
    "    with open(os.path.join(output_dir, 'coarse', 'batches_1-9', f\"annotator{n}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            d = json.loads(line)\n",
    "            if d['rated'] == 'Yes':\n",
    "                d['annotator'] = f\"annotator{n}\"\n",
    "                results.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD BATCH 9 for annotator3\n",
    "with open(os.path.join(output_dir, 'coarse', 'afterapril9', f\"annotator3.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        d = json.loads(line)\n",
    "        if d['rated'] == 'Yes' and (d['batch_id'] == 'batch_7' or d['batch_id'] == 'batch_8' or d['batch_id'] == 'batch_9'):\n",
    "            d['annotator'] = f\"annotator3\"\n",
    "            results.append(d)\n",
    "\n",
    "with open(os.path.join(output_dir, 'coarse', 'afterapril9', f\"annotator6.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        d = json.loads(line)\n",
    "        if d['rated'] == 'Yes' and (d['batch_id'] == 'batch_8' or d['batch_id'] == 'batch_9'):\n",
    "            d['annotator'] = f\"annotator6\"\n",
    "            results.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>annotation_type</th>\n",
       "      <th>rated</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>correctness</th>\n",
       "      <th>relevance</th>\n",
       "      <th>safety</th>\n",
       "      <th>time</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67d43fe8ccebca25cea425dc</td>\n",
       "      <td>question_180</td>\n",
       "      <td>Whats Keratosis Pilaris</td>\n",
       "      <td>gpt4_43</td>\n",
       "      <td>Keratosis Pilaris is a common skin condition c...</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>coarse</td>\n",
       "      <td>Yes</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>Fairly confident</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Partially Disagree</td>\n",
       "      <td>Partially Disagree</td>\n",
       "      <td>25.293506</td>\n",
       "      <td>annotator1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id   question_id                 question answer_id  \\\n",
       "0  67d43fe8ccebca25cea425dc  question_180  Whats Keratosis Pilaris   gpt4_43   \n",
       "\n",
       "                                              answer answer_type  \\\n",
       "0  Keratosis Pilaris is a common skin condition c...        gpt4   \n",
       "\n",
       "  annotation_type rated batch_id        confidence correctness  \\\n",
       "0          coarse   Yes  batch_1  Fairly confident     Neutral   \n",
       "\n",
       "            relevance              safety       time   annotator  \n",
       "0  Partially Disagree  Partially Disagree  25.293506  annotator1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many questions and QA pairs have they already annotated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotator1 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator2 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator3 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator4 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator5 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator6 annotated QA pairs: 81 annotated Qs 27\n"
     ]
    }
   ],
   "source": [
    "annotators = {}\n",
    "for n in range(1,7):\n",
    "    annotator = f'annotator{n}'\n",
    "    annotated_qs = results_df[results_df['annotator'] == annotator]\n",
    "    print(f'annotator{n}', 'annotated QA pairs:', len(annotated_qs), 'annotated Qs', len(annotated_qs.question_id.unique()))\n",
    "    annotators[annotator] = annotated_qs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the overlap between annotators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp1 = np.intersect1d(annotators['annotator1'].question_id, annotators['annotator2'].question_id)\n",
    "len(np.intersect1d(annotators['annotator6'].question_id, grp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp2 = np.intersect1d(annotators['annotator3'].question_id, annotators['annotator4'].question_id)\n",
    "len(np.intersect1d(annotators['annotator5'].question_id, grp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question_ids in coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine question_ids for each annotator\n",
    "groups = {}\n",
    "for n in range(1,7):\n",
    "    with open(os.path.join(output_dir, 'coarse', 'batches_1-9', f\"annotator{n}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            d = json.loads(line)\n",
    "            if f\"annotator{n}\" not in groups.keys():\n",
    "                groups[f\"annotator{n}\"] = []\n",
    "            groups[f\"annotator{n}\"].append(d['question_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find intersection for group 1\n",
    "grp1 = np.intersect1d(set(groups['annotator1']), set(groups['annotator2']))[0]\n",
    "coarse_questions_grp1 = list(np.intersect1d(set(groups['annotator6']), grp1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find intersection for group 2\n",
    "grp2 = np.intersect1d(set(groups['annotator3']), set(groups['annotator4']))[0]\n",
    "coarse_questions_grp2 = list(np.intersect1d(set(groups['annotator5']), grp2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype='<U12')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that groups do not share question_ids\n",
    "np.intersect1d(coarse_questions_grp1, coarse_questions_grp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What questions in Fine Part 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_part_2 = {}\n",
    "for n in range(1,7):\n",
    "    annotator = f'annotator{n}'\n",
    "    fine_part_2[annotator] = []\n",
    "    if n in [1,2,6]:\n",
    "        for q_id in coarse_questions_grp1: # for all questions in coarse\n",
    "            if q_id not in results_df[results_df['annotator'] == annotator].question_id.unique(): # if question not annotated in part 1\n",
    "                fine_part_2[annotator].append(q_id) # append to fin part 1\n",
    "    else:\n",
    "        for q_id in coarse_questions_grp2:\n",
    "            if q_id not in results_df[results_df['annotator'] == annotator].question_id.unique():\n",
    "                fine_part_2[annotator].append(q_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('fine_part_2.json'), 'w') as json_file:\n",
    "    json.dump(fine_part_2, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[]\n",
      "50\n",
      "[]\n",
      "50\n",
      "[]\n",
      "50\n",
      "[]\n",
      "50\n",
      "[]\n",
      "50\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,7):\n",
    "    annotator = f'annotator{n}'\n",
    "    double_check = fine_part_2[annotator].copy() + list(results_df[results_df['annotator'] == annotator].question_id.unique())\n",
    "    print(len(double_check))\n",
    "    if n in [1,2,6]:\n",
    "        print(np.setdiff1d(coarse_questions_grp1, double_check))\n",
    "    else:\n",
    "        print(np.setdiff1d(coarse_questions_grp2, double_check))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df5 = results_df.copy()\n",
    "results_df3 = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings5 = {\"Disagree\": 1,\n",
    "            \"Partially Disagree\": 2,\n",
    "            \"Neutral\": 3,\n",
    "            \"Partially Agree\": 4,\n",
    "            \"Agree\": 5}\n",
    "ratings3 = {\"Disagree\": -1,\n",
    "            \"Partially Disagree\": -1,\n",
    "            \"Neutral\": 0,\n",
    "            \"Partially Agree\": 1,\n",
    "            \"Agree\": 1}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    results_df5[label].replace(ratings5, inplace=True)\n",
    "    results_df3[label].replace(ratings3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_group = [f'annotator{n}' for n in (1,2,6)]\n",
    "second_group = [f'annotator{n}' for n in range(3,6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement with 5-point Likert Scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([i.split('_')[1] for i in results_df5[results_df5['annotator'].isin(first_group)].answer_id.unique()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([i.split('_')[1] for i in results_df5[results_df5['annotator'].isin(second_group)].answer_id.unique()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    question_180\n",
      "7     question_180\n",
      "14    question_180\n",
      "1      question_36\n",
      "9      question_36\n",
      "11     question_36\n",
      "26      question_4\n",
      "17      question_4\n",
      "4       question_4\n",
      "0      question_48\n",
      "15     question_48\n",
      "22     question_48\n",
      "8       question_6\n",
      "21      question_6\n",
      "23      question_6\n",
      "5       question_8\n",
      "20      question_8\n",
      "6       question_8\n",
      "13     question_82\n",
      "19     question_82\n",
      "25     question_82\n",
      "3      question_95\n",
      "2      question_95\n",
      "10     question_95\n",
      "12     question_96\n",
      "24     question_96\n",
      "16     question_96\n",
      "Name: question_id, dtype: object\n",
      "33    question_101\n",
      "34    question_101\n",
      "49    question_101\n",
      "43     question_11\n",
      "42     question_11\n",
      "47     question_11\n",
      "53    question_118\n",
      "28    question_118\n",
      "48    question_118\n",
      "30    question_131\n",
      "44    question_131\n",
      "50    question_131\n",
      "27    question_163\n",
      "45    question_163\n",
      "38    question_163\n",
      "32    question_168\n",
      "29    question_168\n",
      "31    question_168\n",
      "52     question_44\n",
      "46     question_44\n",
      "37     question_44\n",
      "39      question_7\n",
      "51      question_7\n",
      "40      question_7\n",
      "35     question_76\n",
      "36     question_76\n",
      "41     question_76\n",
      "Name: question_id, dtype: object\n",
      "145    question_120\n",
      "142    question_120\n",
      "146    question_120\n",
      "148    question_135\n",
      "155    question_135\n",
      "149    question_135\n",
      "136    question_148\n",
      "161    question_148\n",
      "139    question_148\n",
      "153     question_36\n",
      "143     question_36\n",
      "154     question_36\n",
      "159     question_48\n",
      "156     question_48\n",
      "160     question_48\n",
      "157     question_49\n",
      "147     question_49\n",
      "137     question_49\n",
      "144      question_7\n",
      "135      question_7\n",
      "138      question_7\n",
      "158     question_76\n",
      "141     question_76\n",
      "140     question_76\n",
      "152     question_84\n",
      "150     question_84\n",
      "151     question_84\n",
      "Name: question_id, dtype: object\n",
      "18    question_180\n",
      "7     question_180\n",
      "14    question_180\n",
      "1      question_36\n",
      "9      question_36\n",
      "11     question_36\n",
      "26      question_4\n",
      "17      question_4\n",
      "4       question_4\n",
      "0      question_48\n",
      "15     question_48\n",
      "22     question_48\n",
      "8       question_6\n",
      "21      question_6\n",
      "23      question_6\n",
      "5       question_8\n",
      "20      question_8\n",
      "6       question_8\n",
      "13     question_82\n",
      "19     question_82\n",
      "25     question_82\n",
      "3      question_95\n",
      "2      question_95\n",
      "10     question_95\n",
      "12     question_96\n",
      "24     question_96\n",
      "16     question_96\n",
      "Name: question_id, dtype: object\n",
      "33    question_101\n",
      "34    question_101\n",
      "49    question_101\n",
      "43     question_11\n",
      "42     question_11\n",
      "47     question_11\n",
      "53    question_118\n",
      "28    question_118\n",
      "48    question_118\n",
      "30    question_131\n",
      "44    question_131\n",
      "50    question_131\n",
      "27    question_163\n",
      "45    question_163\n",
      "38    question_163\n",
      "32    question_168\n",
      "29    question_168\n",
      "31    question_168\n",
      "52     question_44\n",
      "46     question_44\n",
      "37     question_44\n",
      "39      question_7\n",
      "51      question_7\n",
      "40      question_7\n",
      "35     question_76\n",
      "36     question_76\n",
      "41     question_76\n",
      "Name: question_id, dtype: object\n",
      "145    question_120\n",
      "142    question_120\n",
      "146    question_120\n",
      "148    question_135\n",
      "155    question_135\n",
      "149    question_135\n",
      "136    question_148\n",
      "161    question_148\n",
      "139    question_148\n",
      "153     question_36\n",
      "143     question_36\n",
      "154     question_36\n",
      "159     question_48\n",
      "156     question_48\n",
      "160     question_48\n",
      "157     question_49\n",
      "147     question_49\n",
      "137     question_49\n",
      "144      question_7\n",
      "135      question_7\n",
      "138      question_7\n",
      "158     question_76\n",
      "141     question_76\n",
      "140     question_76\n",
      "152     question_84\n",
      "150     question_84\n",
      "151     question_84\n",
      "Name: question_id, dtype: object\n",
      "18    question_180\n",
      "7     question_180\n",
      "14    question_180\n",
      "1      question_36\n",
      "9      question_36\n",
      "11     question_36\n",
      "26      question_4\n",
      "17      question_4\n",
      "4       question_4\n",
      "0      question_48\n",
      "15     question_48\n",
      "22     question_48\n",
      "8       question_6\n",
      "21      question_6\n",
      "23      question_6\n",
      "5       question_8\n",
      "20      question_8\n",
      "6       question_8\n",
      "13     question_82\n",
      "19     question_82\n",
      "25     question_82\n",
      "3      question_95\n",
      "2      question_95\n",
      "10     question_95\n",
      "12     question_96\n",
      "24     question_96\n",
      "16     question_96\n",
      "Name: question_id, dtype: object\n",
      "33    question_101\n",
      "34    question_101\n",
      "49    question_101\n",
      "43     question_11\n",
      "42     question_11\n",
      "47     question_11\n",
      "53    question_118\n",
      "28    question_118\n",
      "48    question_118\n",
      "30    question_131\n",
      "44    question_131\n",
      "50    question_131\n",
      "27    question_163\n",
      "45    question_163\n",
      "38    question_163\n",
      "32    question_168\n",
      "29    question_168\n",
      "31    question_168\n",
      "52     question_44\n",
      "46     question_44\n",
      "37     question_44\n",
      "39      question_7\n",
      "51      question_7\n",
      "40      question_7\n",
      "35     question_76\n",
      "36     question_76\n",
      "41     question_76\n",
      "Name: question_id, dtype: object\n",
      "145    question_120\n",
      "142    question_120\n",
      "146    question_120\n",
      "148    question_135\n",
      "155    question_135\n",
      "149    question_135\n",
      "136    question_148\n",
      "161    question_148\n",
      "139    question_148\n",
      "153     question_36\n",
      "143     question_36\n",
      "154     question_36\n",
      "159     question_48\n",
      "156     question_48\n",
      "160     question_48\n",
      "157     question_49\n",
      "147     question_49\n",
      "137     question_49\n",
      "144      question_7\n",
      "135      question_7\n",
      "138      question_7\n",
      "158     question_76\n",
      "141     question_76\n",
      "140     question_76\n",
      "152     question_84\n",
      "150     question_84\n",
      "151     question_84\n",
      "Name: question_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "first_group_d = {}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    first_group_d[label] = {}\n",
    "    for annotator in first_group:\n",
    "        ddf = results_df5[results_df5['annotator'] == annotator].sort_values(['question_id', 'answer_id']).copy()\n",
    "        ann = ddf[label].values.tolist()\n",
    "        first_group_d[label][annotator] = ann\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Krippendorff's alpha -0.17\n",
      "Fleiss' Kappa -0.11\n",
      "Randolph' Kappa 0.26\n",
      "RELEVANCE\n",
      "Krippendorff's alpha 0.02\n",
      "Fleiss' Kappa -0.06\n",
      "Randolph' Kappa 0.2\n",
      "SAFETY\n",
      "Krippendorff's alpha -0.11\n",
      "Fleiss' Kappa -0.02\n",
      "Randolph' Kappa -0.0\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(first_group_d[label])\n",
    "    a = kd.alpha(data.T.values, level_of_measurement='ordinal')\n",
    "    print(\"Krippendorff's alpha\", round(a, 2))\n",
    "    fk = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='fleiss')\n",
    "    print(\"Fleiss' Kappa\", round(fk, 2))\n",
    "    k = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    print(\"Randolph' Kappa\", round(k, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_group_d = {}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    second_group_d[label] = {}\n",
    "    for annotator in second_group:\n",
    "        ddf = results_df5[results_df5['annotator'] == annotator].sort_values(['question_id', 'answer_id']).copy()\n",
    "        ann = ddf[label].values.tolist()\n",
    "        second_group_d[label][annotator] = ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Krippendorff's alpha -0.26\n",
      "Fleiss' Kappa -0.24\n",
      "Randolph' Kappa -0.0\n",
      "RELEVANCE\n",
      "Krippendorff's alpha -0.17\n",
      "Fleiss' Kappa -0.05\n",
      "Randolph' Kappa 0.24\n",
      "SAFETY\n",
      "Krippendorff's alpha -0.16\n",
      "Fleiss' Kappa -0.07\n",
      "Randolph' Kappa -0.0\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(second_group_d[label])\n",
    "    a = kd.alpha(data.T.values, level_of_measurement='ordinal')\n",
    "    print(\"Krippendorff's alpha\", round(a, 2))\n",
    "    fk = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='fleiss')\n",
    "    print(\"Fleiss' Kappa\", round(fk, 2))\n",
    "    k = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    print(\"Randolph' Kappa\", round(k, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            3           5           3           5           4           5\n",
      "1            5           5           4           4           5           5\n",
      "2            5           4           4           4           5           5\n",
      "3            2           5           4           5           5           5\n",
      "4            5           5           5           4           5           5\n",
      "5            3           5           2           5           5           4\n",
      "6            5           5           4           5           5           5\n",
      "7            5           5           4           5           5           5\n",
      "8            4           3           3           5           4           5\n",
      "9            4           5           4           4           5           5\n",
      "10           2           5           3           4           5           5\n",
      "11           2           4           3           4           5           5\n",
      "12           4           5           4           4           5           5\n",
      "13           2           5           5           4           5           5\n",
      "14           4           5           4           4           5           4\n",
      "15           4           5           5           4           5           5\n",
      "16           4           5           4           4           5           5\n",
      "17           4           5           2           4           5           5\n",
      "18           2           5           4           4           5           5\n",
      "19           4           5           5           4           5           5\n",
      "20           5           4           4           4           3           4\n",
      "21           4           5           4           4           5           5\n",
      "22           4           5           5           4           5           5\n",
      "23           5           5           3           4           5           5\n",
      "24           4           5           4           4           5           4\n",
      "25           5           5           3           5           5           5\n",
      "26           2           5           3           4           5           5\n",
      "RELEVANCE\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            2           4           4           5           5           5\n",
      "1            5           4           4           5           5           5\n",
      "2            5           1           5           4           5           5\n",
      "3            2           5           4           5           5           5\n",
      "4            5           5           5           5           5           5\n",
      "5            4           3           3           5           5           4\n",
      "6            5           5           4           5           5           5\n",
      "7            5           5           4           5           5           4\n",
      "8            4           3           3           5           5           5\n",
      "9            4           5           3           5           5           5\n",
      "10           3           5           4           4           5           5\n",
      "11           2           4           2           5           5           4\n",
      "12           4           5           4           4           5           4\n",
      "13           2           4           4           4           5           4\n",
      "14           4           5           3           4           5           4\n",
      "15           4           5           4           5           5           5\n",
      "16           4           5           4           4           5           5\n",
      "17           4           5           2           5           5           5\n",
      "18           4           5           5           4           5           5\n",
      "19           5           4           5           5           5           5\n",
      "20           5           3           4           4           5           4\n",
      "21           5           5           5           5           5           5\n",
      "22           4           5           5           5           5           5\n",
      "23           5           3           2           5           5           4\n",
      "24           4           5           4           4           4           4\n",
      "25           5           4           4           5           5           4\n",
      "26           3           4           2           4           5           4\n",
      "SAFETY\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            2           2           4           1           5           5\n",
      "1            5           4           2           1           5           4\n",
      "2            5           1           3           1           4           5\n",
      "3            3           1           2           4           5           4\n",
      "4            5           4           4           4           5           4\n",
      "5            4           2           2           4           5           4\n",
      "6            5           2           2           1           5           2\n",
      "7            5           2           2           1           5           3\n",
      "8            4           1           2           4           5           1\n",
      "9            4           3           3           4           3           4\n",
      "10           2           1           3           4           3           4\n",
      "11           2           1           1           4           4           4\n",
      "12           4           4           2           4           5           4\n",
      "13           3           5           5           4           5           4\n",
      "14           3           2           2           1           5           3\n",
      "15           3           1           1           1           4           5\n",
      "16           4           2           5           1           5           5\n",
      "17           2           5           1           4           5           4\n",
      "18           2           2           4           4           5           4\n",
      "19           4           2           5           4           5           5\n",
      "20           5           4           2           4           4           4\n",
      "21           2           2           4           4           3           3\n",
      "22           4           2           4           4           4           3\n",
      "23           5           3           1           1           4           1\n",
      "24           3           1           4           1           5           3\n",
      "25           5           1           2           4           4           3\n",
      "26           3           2           2           1           5           5\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement with 3-point Likert Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations3 = {}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    annotations3[label] = {}\n",
    "    for annotator in results_df3.annotator.unique():\n",
    "        ddf = results_df3[results_df3['annotator'] == annotator].sort_values(['question_id', 'answer_id']).copy()\n",
    "        ann = ddf[label].values.tolist()\n",
    "        annotations3[label][annotator] = ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Krippendorff's alpha 0.0132\n",
      "Fleiss' Kappa -0.0049\n",
      "Randolph' Kappa 0.6778\n",
      "RELEVANCE\n",
      "Krippendorff's alpha -0.0093\n",
      "Fleiss' Kappa -0.0042\n",
      "Randolph' Kappa 0.6778\n",
      "SAFETY\n",
      "Krippendorff's alpha -0.0116\n",
      "Fleiss' Kappa -0.0114\n",
      "Randolph' Kappa 0.1222\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    a = kd.alpha(data.T.values, level_of_measurement='ordinal')\n",
    "    print(\"Krippendorff's alpha\", round(a, 4))\n",
    "    fk = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='fleiss')\n",
    "    print(\"Fleiss' Kappa\", round(fk, 4))\n",
    "    k = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    print(\"Randolph' Kappa\", round(k, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying wrong annotator\n",
    "\n",
    "5-POINT LIKERT\n",
    "correctness: annotator 3 (good: annotator 2)\n",
    "relevance: annotator 1 and 4 (good: annotator 3)\n",
    "safety: annotator 6\n",
    "\n",
    "3-POINT LIKERT\n",
    "correctness: bad: annotator 1 and 5\n",
    "relevance: annotator 5 (good: annotator 3 and 4)\n",
    "safety: annotator 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-point Likert scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Full Randolph's Kappa (with all annotators): 0.2000\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.274074                0.0741\n",
      "annotator1                 0.249383                0.0494\n",
      "annotator4                 0.239506                0.0395\n",
      "annotator5                 0.165432               -0.0346\n",
      "annotator2                 0.140741               -0.0593\n",
      "annotator6                 0.130864               -0.0691\n",
      "RELEVANCE\n",
      "Full Randolph's Kappa (with all annotators): 0.3025\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator1                 0.361111                0.0586\n",
      "annotator3                 0.356481                0.0540\n",
      "annotator2                 0.283951               -0.0185\n",
      "annotator5                 0.268519               -0.0340\n",
      "annotator4                 0.254630               -0.0478\n",
      "annotator6                 0.245370               -0.0571\n",
      "SAFETY\n",
      "Full Randolph's Kappa (with all annotators): 0.0247\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator1                 0.060185                0.0355\n",
      "annotator5                 0.041667                0.0170\n",
      "annotator3                 0.027778                0.0031\n",
      "annotator2                 0.023148               -0.0015\n",
      "annotator4                 0.004630               -0.0201\n",
      "annotator6                -0.009259               -0.0340\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "    \n",
    "    full_kappa = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    \n",
    "    kappas_without_each = {}\n",
    "\n",
    "    for annotator in data.T.index:\n",
    "        reduced_data = data.drop(columns=[annotator]).values\n",
    "        kappa_loo = irr.fleiss_kappa(irr.aggregate_raters(reduced_data)[0], method='randolph')\n",
    "        kappas_without_each[annotator] = kappa_loo\n",
    "\n",
    "    # Display results\n",
    "    summary = pd.DataFrame({\n",
    "        'Kappa without Annotator': (kappas_without_each)\n",
    "    })\n",
    "    summary['Delta (Kappa - Full)'] = round(summary['Kappa without Annotator'] - full_kappa, 4)\n",
    "    summary = summary.sort_values(by='Delta (Kappa - Full)', ascending=False)\n",
    "\n",
    "    print(f\"Full Randolph's Kappa (with all annotators): {full_kappa:.4f}\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-point likert scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Full Randolph's Kappa (with all annotators): 0.6778\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.777778                0.1000\n",
      "annotator1                 0.766667                0.0889\n",
      "annotator5                 0.644444               -0.0333\n",
      "annotator2                 0.633333               -0.0444\n",
      "annotator4                 0.622222               -0.0556\n",
      "annotator6                 0.622222               -0.0556\n",
      "RELEVANCE\n",
      "Full Randolph's Kappa (with all annotators): 0.6778\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.755556                0.0778\n",
      "annotator1                 0.738889                0.0611\n",
      "annotator2                 0.705556                0.0278\n",
      "annotator4                 0.622222               -0.0556\n",
      "annotator5                 0.622222               -0.0556\n",
      "annotator6                 0.622222               -0.0556\n",
      "SAFETY\n",
      "Full Randolph's Kappa (with all annotators): 0.1222\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator1                 0.155556                0.0333\n",
      "annotator2                 0.150000                0.0278\n",
      "annotator3                 0.150000                0.0278\n",
      "annotator6                 0.105556               -0.0167\n",
      "annotator5                 0.094444               -0.0278\n",
      "annotator4                 0.077778               -0.0444\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    \n",
    "    full_kappa = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    \n",
    "    kappas_without_each = {}\n",
    "\n",
    "    for annotator in data.T.index:\n",
    "        reduced_data = data.drop(columns=[annotator]).values\n",
    "        kappa_loo = irr.fleiss_kappa(irr.aggregate_raters(reduced_data)[0], method='randolph')\n",
    "        kappas_without_each[annotator] = kappa_loo\n",
    "\n",
    "    # Display results\n",
    "    summary = pd.DataFrame({\n",
    "        'Kappa without Annotator': (kappas_without_each)\n",
    "    })\n",
    "    summary['Delta (Kappa - Full)'] = round(summary['Kappa without Annotator'] - full_kappa, 4)\n",
    "    summary = summary.sort_values(by='Delta (Kappa - Full)', ascending=False)\n",
    "\n",
    "    print(f\"Full Randolph's Kappa (with all annotators): {full_kappa:.4f}\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways of computing disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "            Average Weighted Kappa with Others\n",
      "annotator1                            0.540741\n",
      "annotator3                            0.437037\n",
      "annotator5                            0.229630\n",
      "annotator2                            0.214815\n",
      "annotator4                            0.200000\n",
      "annotator6                            0.200000\n",
      "RELEVANCE\n",
      "            Average Weighted Kappa with Others\n",
      "annotator3                            0.474074\n",
      "annotator1                            0.459259\n",
      "annotator2                            0.340741\n",
      "annotator4                            0.207407\n",
      "annotator5                            0.207407\n",
      "annotator6                            0.207407\n",
      "SAFETY\n",
      "            Average Weighted Kappa with Others\n",
      "annotator2                            1.066667\n",
      "annotator3                            1.051852\n",
      "annotator1                            0.962963\n",
      "annotator5                            0.918519\n",
      "annotator4                            0.903704\n",
      "annotator6                            0.844444\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    kappa_matrix = pd.DataFrame(index=results_df.annotator.unique(), columns=results_df.annotator.unique(), dtype=float)\n",
    "\n",
    "    # Compute pairwise **weighted Cohenâ€™s Kappa**\n",
    "    for a1, a2 in combinations(results_df.annotator.unique(), 2):\n",
    "        #kappa = cohen_kappa_score(data[a1], data[a2], weights='quadratic')  # or 'linear'\n",
    "        mad = np.mean(np.abs(data[a1] - data[a2]))\n",
    "        kappa_matrix.loc[a1, a2] = mad\n",
    "        kappa_matrix.loc[a2, a1] = mad\n",
    "\n",
    "    np.fill_diagonal(kappa_matrix.values, np.nan)\n",
    "\n",
    "    # Compute average agreement per annotator\n",
    "    average_kappa = kappa_matrix.mean(axis=1)\n",
    "    summary = pd.DataFrame({\n",
    "        'Average Weighted Kappa with Others': average_kappa\n",
    "    }).sort_values(by='Average Weighted Kappa with Others', ascending=False)\n",
    "\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Annotators sorted by divergence from consensus (higher MAD = more divergent):\n",
      "    Annotator  Mean Absolute Difference\n",
      "0  annotator1                  0.444444\n",
      "2  annotator3                  0.444444\n",
      "3  annotator4                  0.444444\n",
      "4  annotator5                  0.444444\n",
      "5  annotator6                  0.333333\n",
      "1  annotator2                  0.222222\n",
      "RELEVANCE\n",
      "Annotators sorted by divergence from consensus (higher MAD = more divergent):\n",
      "    Annotator  Mean Absolute Difference\n",
      "0  annotator1                  0.888889\n",
      "5  annotator6                  0.888889\n",
      "3  annotator4                  0.777778\n",
      "4  annotator5                  0.777778\n",
      "1  annotator2                  0.666667\n",
      "2  annotator3                  0.555556\n",
      "SAFETY\n",
      "Annotators sorted by divergence from consensus (higher MAD = more divergent):\n",
      "    Annotator  Mean Absolute Difference\n",
      "5  annotator6                  1.222222\n",
      "3  annotator4                  1.111111\n",
      "0  annotator1                  1.000000\n",
      "2  annotator3                  1.000000\n",
      "4  annotator5                  1.000000\n",
      "1  annotator2                  0.888889\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "\n",
    "    # Dictionary to store MAD scores\n",
    "    mad_scores = {}\n",
    "\n",
    "    # Loop through each annotator\n",
    "    for annotator in data.columns:\n",
    "        # Step 1: Remove current annotator from the data\n",
    "        reduced_data = data.drop(columns=[annotator])\n",
    "        \n",
    "        # Step 2: Compute consensus (mode/majority vote per column)\n",
    "        consensus = reduced_data.mode(axis=1)[0]\n",
    "        \n",
    "        # Step 3: Get annotator's own ratings\n",
    "        annotator_labels = data[annotator]\n",
    "        \n",
    "        # Step 4: Compute mean absolute difference\n",
    "        mad = np.mean(np.abs(annotator_labels - consensus))\n",
    "        mad_scores[annotator] = mad\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    mad_df = pd.DataFrame(list(mad_scores.items()), columns=['Annotator', 'Mean Absolute Difference'])\n",
    "    mad_df = mad_df.sort_values(by='Mean Absolute Difference', ascending=False)\n",
    "\n",
    "    # Show results\n",
    "    print(\"Annotators sorted by divergence from consensus (higher MAD = more divergent):\")\n",
    "    print(mad_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
