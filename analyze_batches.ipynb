{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import inter_rater as irr\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import krippendorff as kd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File locations\n",
    "dir = os.getcwd()\n",
    "output_dir = os.path.join(dir, 'output')\n",
    "fig_dir = os.path.join(dir, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO ASSEMBLE BATCHES\n",
    "for n in range(1,7):\n",
    "    if n not in [1,2,6]:\n",
    "        results = []\n",
    "        with open(os.path.join(output_dir, 'coarse', 'batches_1-9', f\"annotator{n}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "            for line in jsonl_file:\n",
    "                d = json.loads(line)\n",
    "                d['annotator'] = f\"annotator{n}\"\n",
    "                results.append(d)\n",
    "        \n",
    "        output_file = f\"annotator{n}.jsonl\"\n",
    "        with open(os.path.join('output', 'coarse', output_file), 'w', encoding='utf-8') as f:\n",
    "            for doc in results:\n",
    "                f.write(json.dumps(doc, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n in range(1,7):\n",
    "    with open(os.path.join(output_dir, 'coarse', f\"annotator{n}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            d = json.loads(line)\n",
    "            d['annotator'] = f\"annotator{n}\"\n",
    "            results.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>annotation_type</th>\n",
       "      <th>rated</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>correctness</th>\n",
       "      <th>relevance</th>\n",
       "      <th>safety</th>\n",
       "      <th>time</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67d43fe8ccebca25cea425e4</td>\n",
       "      <td>question_48</td>\n",
       "      <td>Does hydroxyzine have any affect on metabolism...</td>\n",
       "      <td>gpt4_45</td>\n",
       "      <td>Hydroxyzine is an antihistamine commonly used ...</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>coarse</td>\n",
       "      <td>Yes</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>Very confident</td>\n",
       "      <td>Partially Agree</td>\n",
       "      <td>Partially Agree</td>\n",
       "      <td>Partially Agree</td>\n",
       "      <td>63.261443</td>\n",
       "      <td>annotator1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  question_id  \\\n",
       "0  67d43fe8ccebca25cea425e4  question_48   \n",
       "\n",
       "                                            question answer_id  \\\n",
       "0  Does hydroxyzine have any affect on metabolism...   gpt4_45   \n",
       "\n",
       "                                              answer answer_type  \\\n",
       "0  Hydroxyzine is an antihistamine commonly used ...        gpt4   \n",
       "\n",
       "  annotation_type rated batch_id      confidence      correctness  \\\n",
       "0          coarse   Yes  batch_1  Very confident  Partially Agree   \n",
       "\n",
       "         relevance           safety       time   annotator  \n",
       "0  Partially Agree  Partially Agree  63.261443  annotator1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df5 = results_df.copy()\n",
    "results_df3 = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings5 = {\"Disagree\": 1,\n",
    "            \"Partially Disagree\": 2,\n",
    "            \"Neutral\": 3,\n",
    "            \"Partially Agree\": 4,\n",
    "            \"Agree\": 5}\n",
    "ratings3 = {\"Disagree\": -1,\n",
    "            \"Partially Disagree\": -1,\n",
    "            \"Neutral\": 0,\n",
    "            \"Partially Agree\": 1,\n",
    "            \"Agree\": 1}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    results_df5[label].replace(ratings5, inplace=True)\n",
    "    results_df3[label].replace(ratings3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_group = [f'annotator{n}' for n in (1,2,6)]\n",
    "second_group = [f'annotator{n}' for n in range(3,6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement with 5-point Likert Scales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([i.split('_')[1] for i in results_df5[results_df5['annotator'].isin(first_group)].answer_id.unique()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([i.split('_')[1] for i in results_df5[results_df5['annotator'].isin(second_group)].answer_id.unique()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    question_180\n",
      "7     question_180\n",
      "14    question_180\n",
      "1      question_36\n",
      "9      question_36\n",
      "11     question_36\n",
      "26      question_4\n",
      "17      question_4\n",
      "4       question_4\n",
      "0      question_48\n",
      "15     question_48\n",
      "22     question_48\n",
      "8       question_6\n",
      "21      question_6\n",
      "23      question_6\n",
      "5       question_8\n",
      "20      question_8\n",
      "6       question_8\n",
      "13     question_82\n",
      "19     question_82\n",
      "25     question_82\n",
      "3      question_95\n",
      "2      question_95\n",
      "10     question_95\n",
      "12     question_96\n",
      "24     question_96\n",
      "16     question_96\n",
      "Name: question_id, dtype: object\n",
      "33    question_101\n",
      "34    question_101\n",
      "49    question_101\n",
      "43     question_11\n",
      "42     question_11\n",
      "47     question_11\n",
      "53    question_118\n",
      "28    question_118\n",
      "48    question_118\n",
      "30    question_131\n",
      "44    question_131\n",
      "50    question_131\n",
      "27    question_163\n",
      "45    question_163\n",
      "38    question_163\n",
      "32    question_168\n",
      "29    question_168\n",
      "31    question_168\n",
      "52     question_44\n",
      "46     question_44\n",
      "37     question_44\n",
      "39      question_7\n",
      "51      question_7\n",
      "40      question_7\n",
      "35     question_76\n",
      "36     question_76\n",
      "41     question_76\n",
      "Name: question_id, dtype: object\n",
      "145    question_120\n",
      "142    question_120\n",
      "146    question_120\n",
      "148    question_135\n",
      "155    question_135\n",
      "149    question_135\n",
      "136    question_148\n",
      "161    question_148\n",
      "139    question_148\n",
      "153     question_36\n",
      "143     question_36\n",
      "154     question_36\n",
      "159     question_48\n",
      "156     question_48\n",
      "160     question_48\n",
      "157     question_49\n",
      "147     question_49\n",
      "137     question_49\n",
      "144      question_7\n",
      "135      question_7\n",
      "138      question_7\n",
      "158     question_76\n",
      "141     question_76\n",
      "140     question_76\n",
      "152     question_84\n",
      "150     question_84\n",
      "151     question_84\n",
      "Name: question_id, dtype: object\n",
      "18    question_180\n",
      "7     question_180\n",
      "14    question_180\n",
      "1      question_36\n",
      "9      question_36\n",
      "11     question_36\n",
      "26      question_4\n",
      "17      question_4\n",
      "4       question_4\n",
      "0      question_48\n",
      "15     question_48\n",
      "22     question_48\n",
      "8       question_6\n",
      "21      question_6\n",
      "23      question_6\n",
      "5       question_8\n",
      "20      question_8\n",
      "6       question_8\n",
      "13     question_82\n",
      "19     question_82\n",
      "25     question_82\n",
      "3      question_95\n",
      "2      question_95\n",
      "10     question_95\n",
      "12     question_96\n",
      "24     question_96\n",
      "16     question_96\n",
      "Name: question_id, dtype: object\n",
      "33    question_101\n",
      "34    question_101\n",
      "49    question_101\n",
      "43     question_11\n",
      "42     question_11\n",
      "47     question_11\n",
      "53    question_118\n",
      "28    question_118\n",
      "48    question_118\n",
      "30    question_131\n",
      "44    question_131\n",
      "50    question_131\n",
      "27    question_163\n",
      "45    question_163\n",
      "38    question_163\n",
      "32    question_168\n",
      "29    question_168\n",
      "31    question_168\n",
      "52     question_44\n",
      "46     question_44\n",
      "37     question_44\n",
      "39      question_7\n",
      "51      question_7\n",
      "40      question_7\n",
      "35     question_76\n",
      "36     question_76\n",
      "41     question_76\n",
      "Name: question_id, dtype: object\n",
      "145    question_120\n",
      "142    question_120\n",
      "146    question_120\n",
      "148    question_135\n",
      "155    question_135\n",
      "149    question_135\n",
      "136    question_148\n",
      "161    question_148\n",
      "139    question_148\n",
      "153     question_36\n",
      "143     question_36\n",
      "154     question_36\n",
      "159     question_48\n",
      "156     question_48\n",
      "160     question_48\n",
      "157     question_49\n",
      "147     question_49\n",
      "137     question_49\n",
      "144      question_7\n",
      "135      question_7\n",
      "138      question_7\n",
      "158     question_76\n",
      "141     question_76\n",
      "140     question_76\n",
      "152     question_84\n",
      "150     question_84\n",
      "151     question_84\n",
      "Name: question_id, dtype: object\n",
      "18    question_180\n",
      "7     question_180\n",
      "14    question_180\n",
      "1      question_36\n",
      "9      question_36\n",
      "11     question_36\n",
      "26      question_4\n",
      "17      question_4\n",
      "4       question_4\n",
      "0      question_48\n",
      "15     question_48\n",
      "22     question_48\n",
      "8       question_6\n",
      "21      question_6\n",
      "23      question_6\n",
      "5       question_8\n",
      "20      question_8\n",
      "6       question_8\n",
      "13     question_82\n",
      "19     question_82\n",
      "25     question_82\n",
      "3      question_95\n",
      "2      question_95\n",
      "10     question_95\n",
      "12     question_96\n",
      "24     question_96\n",
      "16     question_96\n",
      "Name: question_id, dtype: object\n",
      "33    question_101\n",
      "34    question_101\n",
      "49    question_101\n",
      "43     question_11\n",
      "42     question_11\n",
      "47     question_11\n",
      "53    question_118\n",
      "28    question_118\n",
      "48    question_118\n",
      "30    question_131\n",
      "44    question_131\n",
      "50    question_131\n",
      "27    question_163\n",
      "45    question_163\n",
      "38    question_163\n",
      "32    question_168\n",
      "29    question_168\n",
      "31    question_168\n",
      "52     question_44\n",
      "46     question_44\n",
      "37     question_44\n",
      "39      question_7\n",
      "51      question_7\n",
      "40      question_7\n",
      "35     question_76\n",
      "36     question_76\n",
      "41     question_76\n",
      "Name: question_id, dtype: object\n",
      "145    question_120\n",
      "142    question_120\n",
      "146    question_120\n",
      "148    question_135\n",
      "155    question_135\n",
      "149    question_135\n",
      "136    question_148\n",
      "161    question_148\n",
      "139    question_148\n",
      "153     question_36\n",
      "143     question_36\n",
      "154     question_36\n",
      "159     question_48\n",
      "156     question_48\n",
      "160     question_48\n",
      "157     question_49\n",
      "147     question_49\n",
      "137     question_49\n",
      "144      question_7\n",
      "135      question_7\n",
      "138      question_7\n",
      "158     question_76\n",
      "141     question_76\n",
      "140     question_76\n",
      "152     question_84\n",
      "150     question_84\n",
      "151     question_84\n",
      "Name: question_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "first_group_d = {}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    first_group_d[label] = {}\n",
    "    for annotator in first_group:\n",
    "        ddf = results_df5[results_df5['annotator'] == annotator].sort_values(['question_id', 'answer_id']).copy()\n",
    "        ann = ddf[label].values.tolist()\n",
    "        first_group_d[label][annotator] = ann\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Krippendorff's alpha -0.17\n",
      "Fleiss' Kappa -0.11\n",
      "Randolph' Kappa 0.26\n",
      "RELEVANCE\n",
      "Krippendorff's alpha 0.02\n",
      "Fleiss' Kappa -0.06\n",
      "Randolph' Kappa 0.2\n",
      "SAFETY\n",
      "Krippendorff's alpha -0.11\n",
      "Fleiss' Kappa -0.02\n",
      "Randolph' Kappa -0.0\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(first_group_d[label])\n",
    "    a = kd.alpha(data.T.values, level_of_measurement='ordinal')\n",
    "    print(\"Krippendorff's alpha\", round(a, 2))\n",
    "    fk = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='fleiss')\n",
    "    print(\"Fleiss' Kappa\", round(fk, 2))\n",
    "    k = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    print(\"Randolph' Kappa\", round(k, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_group_d = {}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    second_group_d[label] = {}\n",
    "    for annotator in second_group:\n",
    "        ddf = results_df5[results_df5['annotator'] == annotator].sort_values(['question_id', 'answer_id']).copy()\n",
    "        ann = ddf[label].values.tolist()\n",
    "        second_group_d[label][annotator] = ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Krippendorff's alpha -0.26\n",
      "Fleiss' Kappa -0.24\n",
      "Randolph' Kappa -0.0\n",
      "RELEVANCE\n",
      "Krippendorff's alpha -0.17\n",
      "Fleiss' Kappa -0.05\n",
      "Randolph' Kappa 0.24\n",
      "SAFETY\n",
      "Krippendorff's alpha -0.16\n",
      "Fleiss' Kappa -0.07\n",
      "Randolph' Kappa -0.0\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(second_group_d[label])\n",
    "    a = kd.alpha(data.T.values, level_of_measurement='ordinal')\n",
    "    print(\"Krippendorff's alpha\", round(a, 2))\n",
    "    fk = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='fleiss')\n",
    "    print(\"Fleiss' Kappa\", round(fk, 2))\n",
    "    k = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    print(\"Randolph' Kappa\", round(k, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            3           5           3           5           4           5\n",
      "1            5           5           4           4           5           5\n",
      "2            5           4           4           4           5           5\n",
      "3            2           5           4           5           5           5\n",
      "4            5           5           5           4           5           5\n",
      "5            3           5           2           5           5           4\n",
      "6            5           5           4           5           5           5\n",
      "7            5           5           4           5           5           5\n",
      "8            4           3           3           5           4           5\n",
      "9            4           5           4           4           5           5\n",
      "10           2           5           3           4           5           5\n",
      "11           2           4           3           4           5           5\n",
      "12           4           5           4           4           5           5\n",
      "13           2           5           5           4           5           5\n",
      "14           4           5           4           4           5           4\n",
      "15           4           5           5           4           5           5\n",
      "16           4           5           4           4           5           5\n",
      "17           4           5           2           4           5           5\n",
      "18           2           5           4           4           5           5\n",
      "19           4           5           5           4           5           5\n",
      "20           5           4           4           4           3           4\n",
      "21           4           5           4           4           5           5\n",
      "22           4           5           5           4           5           5\n",
      "23           5           5           3           4           5           5\n",
      "24           4           5           4           4           5           4\n",
      "25           5           5           3           5           5           5\n",
      "26           2           5           3           4           5           5\n",
      "RELEVANCE\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            2           4           4           5           5           5\n",
      "1            5           4           4           5           5           5\n",
      "2            5           1           5           4           5           5\n",
      "3            2           5           4           5           5           5\n",
      "4            5           5           5           5           5           5\n",
      "5            4           3           3           5           5           4\n",
      "6            5           5           4           5           5           5\n",
      "7            5           5           4           5           5           4\n",
      "8            4           3           3           5           5           5\n",
      "9            4           5           3           5           5           5\n",
      "10           3           5           4           4           5           5\n",
      "11           2           4           2           5           5           4\n",
      "12           4           5           4           4           5           4\n",
      "13           2           4           4           4           5           4\n",
      "14           4           5           3           4           5           4\n",
      "15           4           5           4           5           5           5\n",
      "16           4           5           4           4           5           5\n",
      "17           4           5           2           5           5           5\n",
      "18           4           5           5           4           5           5\n",
      "19           5           4           5           5           5           5\n",
      "20           5           3           4           4           5           4\n",
      "21           5           5           5           5           5           5\n",
      "22           4           5           5           5           5           5\n",
      "23           5           3           2           5           5           4\n",
      "24           4           5           4           4           4           4\n",
      "25           5           4           4           5           5           4\n",
      "26           3           4           2           4           5           4\n",
      "SAFETY\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            2           2           4           1           5           5\n",
      "1            5           4           2           1           5           4\n",
      "2            5           1           3           1           4           5\n",
      "3            3           1           2           4           5           4\n",
      "4            5           4           4           4           5           4\n",
      "5            4           2           2           4           5           4\n",
      "6            5           2           2           1           5           2\n",
      "7            5           2           2           1           5           3\n",
      "8            4           1           2           4           5           1\n",
      "9            4           3           3           4           3           4\n",
      "10           2           1           3           4           3           4\n",
      "11           2           1           1           4           4           4\n",
      "12           4           4           2           4           5           4\n",
      "13           3           5           5           4           5           4\n",
      "14           3           2           2           1           5           3\n",
      "15           3           1           1           1           4           5\n",
      "16           4           2           5           1           5           5\n",
      "17           2           5           1           4           5           4\n",
      "18           2           2           4           4           5           4\n",
      "19           4           2           5           4           5           5\n",
      "20           5           4           2           4           4           4\n",
      "21           2           2           4           4           3           3\n",
      "22           4           2           4           4           4           3\n",
      "23           5           3           1           1           4           1\n",
      "24           3           1           4           1           5           3\n",
      "25           5           1           2           4           4           3\n",
      "26           3           2           2           1           5           5\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement with 3-point Likert Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations3 = {}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    annotations3[label] = {}\n",
    "    for annotator in results_df3.annotator.unique():\n",
    "        ddf = results_df3[results_df3['annotator'] == annotator].sort_values(['question_id', 'answer_id']).copy()\n",
    "        ann = ddf[label].values.tolist()\n",
    "        annotations3[label][annotator] = ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Krippendorff's alpha 0.0132\n",
      "Fleiss' Kappa -0.0049\n",
      "Randolph' Kappa 0.6778\n",
      "RELEVANCE\n",
      "Krippendorff's alpha -0.0093\n",
      "Fleiss' Kappa -0.0042\n",
      "Randolph' Kappa 0.6778\n",
      "SAFETY\n",
      "Krippendorff's alpha -0.0116\n",
      "Fleiss' Kappa -0.0114\n",
      "Randolph' Kappa 0.1222\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    a = kd.alpha(data.T.values, level_of_measurement='ordinal')\n",
    "    print(\"Krippendorff's alpha\", round(a, 4))\n",
    "    fk = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='fleiss')\n",
    "    print(\"Fleiss' Kappa\", round(fk, 4))\n",
    "    k = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    print(\"Randolph' Kappa\", round(k, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying wrong annotator\n",
    "\n",
    "5-POINT LIKERT\n",
    "correctness: annotator 3 (good: annotator 2)\n",
    "relevance: annotator 1 and 4 (good: annotator 3)\n",
    "safety: annotator 6\n",
    "\n",
    "3-POINT LIKERT\n",
    "correctness: bad: annotator 1 and 5\n",
    "relevance: annotator 5 (good: annotator 3 and 4)\n",
    "safety: annotator 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-point Likert scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Full Randolph's Kappa (with all annotators): 0.2000\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.274074                0.0741\n",
      "annotator1                 0.249383                0.0494\n",
      "annotator4                 0.239506                0.0395\n",
      "annotator5                 0.165432               -0.0346\n",
      "annotator2                 0.140741               -0.0593\n",
      "annotator6                 0.130864               -0.0691\n",
      "RELEVANCE\n",
      "Full Randolph's Kappa (with all annotators): 0.3025\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator1                 0.361111                0.0586\n",
      "annotator3                 0.356481                0.0540\n",
      "annotator2                 0.283951               -0.0185\n",
      "annotator5                 0.268519               -0.0340\n",
      "annotator4                 0.254630               -0.0478\n",
      "annotator6                 0.245370               -0.0571\n",
      "SAFETY\n",
      "Full Randolph's Kappa (with all annotators): 0.0247\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator1                 0.060185                0.0355\n",
      "annotator5                 0.041667                0.0170\n",
      "annotator3                 0.027778                0.0031\n",
      "annotator2                 0.023148               -0.0015\n",
      "annotator4                 0.004630               -0.0201\n",
      "annotator6                -0.009259               -0.0340\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "    \n",
    "    full_kappa = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    \n",
    "    kappas_without_each = {}\n",
    "\n",
    "    for annotator in data.T.index:\n",
    "        reduced_data = data.drop(columns=[annotator]).values\n",
    "        kappa_loo = irr.fleiss_kappa(irr.aggregate_raters(reduced_data)[0], method='randolph')\n",
    "        kappas_without_each[annotator] = kappa_loo\n",
    "\n",
    "    # Display results\n",
    "    summary = pd.DataFrame({\n",
    "        'Kappa without Annotator': (kappas_without_each)\n",
    "    })\n",
    "    summary['Delta (Kappa - Full)'] = round(summary['Kappa without Annotator'] - full_kappa, 4)\n",
    "    summary = summary.sort_values(by='Delta (Kappa - Full)', ascending=False)\n",
    "\n",
    "    print(f\"Full Randolph's Kappa (with all annotators): {full_kappa:.4f}\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-point likert scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Full Randolph's Kappa (with all annotators): 0.6778\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.777778                0.1000\n",
      "annotator1                 0.766667                0.0889\n",
      "annotator5                 0.644444               -0.0333\n",
      "annotator2                 0.633333               -0.0444\n",
      "annotator4                 0.622222               -0.0556\n",
      "annotator6                 0.622222               -0.0556\n",
      "RELEVANCE\n",
      "Full Randolph's Kappa (with all annotators): 0.6778\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.755556                0.0778\n",
      "annotator1                 0.738889                0.0611\n",
      "annotator2                 0.705556                0.0278\n",
      "annotator4                 0.622222               -0.0556\n",
      "annotator5                 0.622222               -0.0556\n",
      "annotator6                 0.622222               -0.0556\n",
      "SAFETY\n",
      "Full Randolph's Kappa (with all annotators): 0.1222\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator1                 0.155556                0.0333\n",
      "annotator2                 0.150000                0.0278\n",
      "annotator3                 0.150000                0.0278\n",
      "annotator6                 0.105556               -0.0167\n",
      "annotator5                 0.094444               -0.0278\n",
      "annotator4                 0.077778               -0.0444\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    \n",
    "    full_kappa = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    \n",
    "    kappas_without_each = {}\n",
    "\n",
    "    for annotator in data.T.index:\n",
    "        reduced_data = data.drop(columns=[annotator]).values\n",
    "        kappa_loo = irr.fleiss_kappa(irr.aggregate_raters(reduced_data)[0], method='randolph')\n",
    "        kappas_without_each[annotator] = kappa_loo\n",
    "\n",
    "    # Display results\n",
    "    summary = pd.DataFrame({\n",
    "        'Kappa without Annotator': (kappas_without_each)\n",
    "    })\n",
    "    summary['Delta (Kappa - Full)'] = round(summary['Kappa without Annotator'] - full_kappa, 4)\n",
    "    summary = summary.sort_values(by='Delta (Kappa - Full)', ascending=False)\n",
    "\n",
    "    print(f\"Full Randolph's Kappa (with all annotators): {full_kappa:.4f}\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways of computing disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "            Average Weighted Kappa with Others\n",
      "annotator1                            0.540741\n",
      "annotator3                            0.437037\n",
      "annotator5                            0.229630\n",
      "annotator2                            0.214815\n",
      "annotator4                            0.200000\n",
      "annotator6                            0.200000\n",
      "RELEVANCE\n",
      "            Average Weighted Kappa with Others\n",
      "annotator3                            0.474074\n",
      "annotator1                            0.459259\n",
      "annotator2                            0.340741\n",
      "annotator4                            0.207407\n",
      "annotator5                            0.207407\n",
      "annotator6                            0.207407\n",
      "SAFETY\n",
      "            Average Weighted Kappa with Others\n",
      "annotator2                            1.066667\n",
      "annotator3                            1.051852\n",
      "annotator1                            0.962963\n",
      "annotator5                            0.918519\n",
      "annotator4                            0.903704\n",
      "annotator6                            0.844444\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    kappa_matrix = pd.DataFrame(index=results_df.annotator.unique(), columns=results_df.annotator.unique(), dtype=float)\n",
    "\n",
    "    # Compute pairwise **weighted Cohen’s Kappa**\n",
    "    for a1, a2 in combinations(results_df.annotator.unique(), 2):\n",
    "        #kappa = cohen_kappa_score(data[a1], data[a2], weights='quadratic')  # or 'linear'\n",
    "        mad = np.mean(np.abs(data[a1] - data[a2]))\n",
    "        kappa_matrix.loc[a1, a2] = mad\n",
    "        kappa_matrix.loc[a2, a1] = mad\n",
    "\n",
    "    np.fill_diagonal(kappa_matrix.values, np.nan)\n",
    "\n",
    "    # Compute average agreement per annotator\n",
    "    average_kappa = kappa_matrix.mean(axis=1)\n",
    "    summary = pd.DataFrame({\n",
    "        'Average Weighted Kappa with Others': average_kappa\n",
    "    }).sort_values(by='Average Weighted Kappa with Others', ascending=False)\n",
    "\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Annotators sorted by divergence from consensus (higher MAD = more divergent):\n",
      "    Annotator  Mean Absolute Difference\n",
      "0  annotator1                  0.444444\n",
      "2  annotator3                  0.444444\n",
      "3  annotator4                  0.444444\n",
      "4  annotator5                  0.444444\n",
      "5  annotator6                  0.333333\n",
      "1  annotator2                  0.222222\n",
      "RELEVANCE\n",
      "Annotators sorted by divergence from consensus (higher MAD = more divergent):\n",
      "    Annotator  Mean Absolute Difference\n",
      "0  annotator1                  0.888889\n",
      "5  annotator6                  0.888889\n",
      "3  annotator4                  0.777778\n",
      "4  annotator5                  0.777778\n",
      "1  annotator2                  0.666667\n",
      "2  annotator3                  0.555556\n",
      "SAFETY\n",
      "Annotators sorted by divergence from consensus (higher MAD = more divergent):\n",
      "    Annotator  Mean Absolute Difference\n",
      "5  annotator6                  1.222222\n",
      "3  annotator4                  1.111111\n",
      "0  annotator1                  1.000000\n",
      "2  annotator3                  1.000000\n",
      "4  annotator5                  1.000000\n",
      "1  annotator2                  0.888889\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "\n",
    "    # Dictionary to store MAD scores\n",
    "    mad_scores = {}\n",
    "\n",
    "    # Loop through each annotator\n",
    "    for annotator in data.columns:\n",
    "        # Step 1: Remove current annotator from the data\n",
    "        reduced_data = data.drop(columns=[annotator])\n",
    "        \n",
    "        # Step 2: Compute consensus (mode/majority vote per column)\n",
    "        consensus = reduced_data.mode(axis=1)[0]\n",
    "        \n",
    "        # Step 3: Get annotator's own ratings\n",
    "        annotator_labels = data[annotator]\n",
    "        \n",
    "        # Step 4: Compute mean absolute difference\n",
    "        mad = np.mean(np.abs(annotator_labels - consensus))\n",
    "        mad_scores[annotator] = mad\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    mad_df = pd.DataFrame(list(mad_scores.items()), columns=['Annotator', 'Mean Absolute Difference'])\n",
    "    mad_df = mad_df.sort_values(by='Mean Absolute Difference', ascending=False)\n",
    "\n",
    "    # Show results\n",
    "    print(\"Annotators sorted by divergence from consensus (higher MAD = more divergent):\")\n",
    "    print(mad_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
