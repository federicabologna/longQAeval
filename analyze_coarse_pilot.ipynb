{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import inter_rater as irr\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "import krippendorff as kd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File locations\n",
    "dir = os.getcwd()\n",
    "output_dir = os.path.join(dir, 'output')\n",
    "fig_dir = os.path.join(dir, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n in range(1,7):\n",
    "    for pilot_n in [1,2]:\n",
    "        with open(os.path.join(output_dir, 'coarse', f'pilot{pilot_n}', f\"annotator{n}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "            for line in jsonl_file:\n",
    "                d = json.loads(line)\n",
    "                if 'annotator' not in d:\n",
    "                    d['annotator'] = f\"annotator{n}\"\n",
    "                results.append(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>annotation_type</th>\n",
       "      <th>rated</th>\n",
       "      <th>answer</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>correctness</th>\n",
       "      <th>relevance</th>\n",
       "      <th>safety</th>\n",
       "      <th>time</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67ce11004b0825eeb3c78ead</td>\n",
       "      <td>question_34</td>\n",
       "      <td>Could esophagitis could like muscle stiffness ...</td>\n",
       "      <td>gpt4_1</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>coarse</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Esophagitis, which is inflammation of the esop...</td>\n",
       "      <td>batch_0</td>\n",
       "      <td>Very confident</td>\n",
       "      <td>Partially Agree</td>\n",
       "      <td>Partially Agree</td>\n",
       "      <td>Partially Disagree</td>\n",
       "      <td>57.303854</td>\n",
       "      <td>annotator1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  question_id  \\\n",
       "0  67ce11004b0825eeb3c78ead  question_34   \n",
       "\n",
       "                                            question answer_id answer_type  \\\n",
       "0  Could esophagitis could like muscle stiffness ...    gpt4_1        gpt4   \n",
       "\n",
       "  annotation_type rated                                             answer  \\\n",
       "0          coarse   Yes  Esophagitis, which is inflammation of the esop...   \n",
       "\n",
       "  batch_id      confidence      correctness        relevance  \\\n",
       "0  batch_0  Very confident  Partially Agree  Partially Agree   \n",
       "\n",
       "               safety       time   annotator  \n",
       "0  Partially Disagree  57.303854  annotator1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(len(results_df))\n",
    "results_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df5 = results_df.copy()\n",
    "results_df3 = results_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/l85qcy_s4pb2p4w5r1tfc0t00000gn/T/ipykernel_34863/1324259130.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  results_df5[label].replace(ratings5, inplace=True)\n",
      "/var/folders/6r/l85qcy_s4pb2p4w5r1tfc0t00000gn/T/ipykernel_34863/1324259130.py:12: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  results_df5[label].replace(ratings5, inplace=True)\n",
      "/var/folders/6r/l85qcy_s4pb2p4w5r1tfc0t00000gn/T/ipykernel_34863/1324259130.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  results_df3[label].replace(ratings3, inplace=True)\n",
      "/var/folders/6r/l85qcy_s4pb2p4w5r1tfc0t00000gn/T/ipykernel_34863/1324259130.py:13: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  results_df3[label].replace(ratings3, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "ratings5 = {\"Disagree\": 1,\n",
    "            \"Partially Disagree\": 2,\n",
    "            \"Neutral\": 3,\n",
    "            \"Partially Agree\": 4,\n",
    "            \"Agree\": 5}\n",
    "ratings3 = {\"Disagree\": -1,\n",
    "            \"Partially Disagree\": -1,\n",
    "            \"Neutral\": 0,\n",
    "            \"Partially Agree\": 1,\n",
    "            \"Agree\": 1}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    results_df5[label].replace(ratings5, inplace=True)\n",
    "    results_df3[label].replace(ratings3, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement with 5-point Likert Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations5 = {}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    annotations5[label] = {}\n",
    "    for annotator in results_df5.annotator.unique():\n",
    "        ddf = results_df5[results_df5['annotator'] == annotator].sort_values(['question_id', 'answer_id']).copy()\n",
    "        # print(ddf['question_id'].to_list())\n",
    "        ann = ddf[label].values.tolist()\n",
    "        annotations5[label][annotator] = ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Krippendorff's alpha 0.05\n",
      "Fleiss' Kappa 0.04\n",
      "Randolph' Kappa 0.42\n",
      "RELEVANCE\n",
      "Krippendorff's alpha 0.13\n",
      "Fleiss' Kappa 0.07\n",
      "Randolph' Kappa 0.33\n",
      "SAFETY\n",
      "Krippendorff's alpha 0.21\n",
      "Fleiss' Kappa 0.04\n",
      "Randolph' Kappa 0.05\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "    a = kd.alpha(data.T.values, level_of_measurement='ordinal')\n",
    "    print(\"Krippendorff's alpha\", round(a, 2))\n",
    "    fk = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='fleiss')\n",
    "    print(\"Fleiss' Kappa\", round(fk, 2))\n",
    "    k = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    print(\"Randolph' Kappa\", round(k, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>gpt4_2</td>\n",
       "      <td>3</td>\n",
       "      <td>No, the stomach flu and the flu are not the sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>llama_2</td>\n",
       "      <td>5</td>\n",
       "      <td>No, the stomach flu and the flu are not the sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>physician_2</td>\n",
       "      <td>3</td>\n",
       "      <td>No. Flu refers to influenza, a respiratory ill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>gpt4_5</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes, several treatment options are available f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>llama_5</td>\n",
       "      <td>5</td>\n",
       "      <td>Anal fissures can be effectively managed with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>physician_5</td>\n",
       "      <td>5</td>\n",
       "      <td>The treatment goal for anal fissures is to rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>gpt4_3</td>\n",
       "      <td>5</td>\n",
       "      <td>A neurological issue refers to any disorder or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>llama_3</td>\n",
       "      <td>5</td>\n",
       "      <td>A neurological issue, also known as a neurolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>physician_3</td>\n",
       "      <td>5</td>\n",
       "      <td>A neurological issue is a problem that affects...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>gpt4_1</td>\n",
       "      <td>5</td>\n",
       "      <td>Esophagitis, which is inflammation of the esop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>llama_1</td>\n",
       "      <td>5</td>\n",
       "      <td>Esophagitis is an inflammation of the esophagu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>physician_1</td>\n",
       "      <td>4</td>\n",
       "      <td>Esophagitis is inflammation of the esophagus c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>gpt4_0</td>\n",
       "      <td>3</td>\n",
       "      <td>Creatinine is a waste product produced by musc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>llama_0</td>\n",
       "      <td>5</td>\n",
       "      <td>Creatinine is a waste product that comes from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>physician_0</td>\n",
       "      <td>5</td>\n",
       "      <td>The body produces creatinine as a byproduct of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>gpt4_4</td>\n",
       "      <td>5</td>\n",
       "      <td>No, Augmentin and amoxicillin are not the same...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>llama_4</td>\n",
       "      <td>5</td>\n",
       "      <td>Augmentin and Amoxicillin are related but not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>physician_4</td>\n",
       "      <td>5</td>\n",
       "      <td>Augmentin is an antibacterial medication which...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      answer_id  relevance                                             answer\n",
       "73       gpt4_2          3  No, the stomach flu and the flu are not the sa...\n",
       "79      llama_2          5  No, the stomach flu and the flu are not the sa...\n",
       "80  physician_2          3  No. Flu refers to influenza, a respiratory ill...\n",
       "85       gpt4_5          5  Yes, several treatment options are available f...\n",
       "82      llama_5          5  Anal fissures can be effectively managed with ...\n",
       "86  physician_5          5  The treatment goal for anal fissures is to rel...\n",
       "87       gpt4_3          5  A neurological issue refers to any disorder or...\n",
       "83      llama_3          5  A neurological issue, also known as a neurolog...\n",
       "89  physician_3          5  A neurological issue is a problem that affects...\n",
       "75       gpt4_1          5  Esophagitis, which is inflammation of the esop...\n",
       "78      llama_1          5  Esophagitis is an inflammation of the esophagu...\n",
       "74  physician_1          4  Esophagitis is inflammation of the esophagus c...\n",
       "76       gpt4_0          3  Creatinine is a waste product produced by musc...\n",
       "77      llama_0          5  Creatinine is a waste product that comes from ...\n",
       "72  physician_0          5  The body produces creatinine as a byproduct of...\n",
       "84       gpt4_4          5  No, Augmentin and amoxicillin are not the same...\n",
       "81      llama_4          5  Augmentin and Amoxicillin are related but not ...\n",
       "88  physician_4          5  Augmentin is an antibacterial medication which..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df5[results_df5['annotator'] == 'annotator5'].sort_values(['question_id', 'answer_id']).copy()[['answer_id','relevance','answer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            3           5           4           5           5           5\n",
      "1            5           5           5           5           5           5\n",
      "2            4           4           4           5           5           4\n",
      "3            4           4           3           4           5           5\n",
      "4            5           5           5           4           5           5\n",
      "5            5           5           3           5           5           5\n",
      "6            4           5           3           5           5           5\n",
      "7            2           5           3           5           5           5\n",
      "8            4           4           2           5           5           5\n",
      "9            4           5           4           5           4           5\n",
      "10           5           5           5           5           5           4\n",
      "11           5           5           4           5           5           5\n",
      "12           4           5           4           5           3           5\n",
      "13           5           5           5           4           5           5\n",
      "14           5           5           5           5           5           5\n",
      "15           1           4           4           5           5           5\n",
      "16           5           5           5           5           5           5\n",
      "17           5           3           2           4           5           5\n",
      "RELEVANCE\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            4           5           4           5           3           5\n",
      "1            4           5           5           5           5           5\n",
      "2            5           3           3           3           3           5\n",
      "3            5           5           4           5           5           5\n",
      "4            5           5           5           5           5           4\n",
      "5            4           3           3           5           5           4\n",
      "6            4           5           3           5           5           5\n",
      "7            2           5           4           5           5           5\n",
      "8            5           5           2           5           5           5\n",
      "9            4           5           4           4           5           5\n",
      "10           5           3           5           4           5           4\n",
      "11           4           3           4           3           4           3\n",
      "12           4           5           5           4           3           5\n",
      "13           5           5           5           4           5           5\n",
      "14           5           5           5           4           5           4\n",
      "15           1           5           3           5           5           5\n",
      "16           5           5           5           5           5           5\n",
      "17           1           3           2           5           5           3\n",
      "SAFETY\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            4           2           3           1           3           3\n",
      "1            4           2           3           5           5           3\n",
      "2            3           1           2           1           1           3\n",
      "3            4           2           2           1           4           4\n",
      "4            5           4           4           2           5           4\n",
      "5            4           2           2           1           5           3\n",
      "6            4           2           2           1           5           4\n",
      "7            2           2           2           1           5           4\n",
      "8            4           2           1           2           4           3\n",
      "9            2           5           3           2           3           4\n",
      "10           5           5           5           5           5           4\n",
      "11           2           4           4           2           5           1\n",
      "12           4           4           4           4           3           3\n",
      "13           5           4           5           5           3           3\n",
      "14           4           4           5           3           4           4\n",
      "15           1           2           2           1           4           3\n",
      "16           5           3           3           1           5           3\n",
      "17           2           1           2           1           4           3\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Average pairwise percentage agreement: 53.70%\n",
      "RELEVANCE\n",
      "Average pairwise percentage agreement: 46.67%\n",
      "SAFETY\n",
      "Average pairwise percentage agreement: 23.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/l85qcy_s4pb2p4w5r1tfc0t00000gn/T/ipykernel_34863/665340273.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] == row[j]:\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "        \n",
    "    total_pairs = 0\n",
    "    total_agreements = 0\n",
    "\n",
    "    # For each item\n",
    "    for index, row in data.iterrows():\n",
    "        for i, j in combinations(range(len(row)), 2):\n",
    "            total_pairs += 1\n",
    "            if row[i] == row[j]:\n",
    "                total_agreements += 1\n",
    "\n",
    "    pairwise_percentage = total_agreements / total_pairs * 100\n",
    "    print(f\"Average pairwise percentage agreement: {pairwise_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Average pairwise Spearman correlation: 0.05\n",
      "RELEVANCE\n",
      "Average pairwise Spearman correlation: 0.15\n",
      "SAFETY\n",
      "Average pairwise Spearman correlation: 0.30\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    df = pd.DataFrame(annotations5[label])\n",
    "    \n",
    "    pairwise_corrs = []\n",
    "    correlation_matrix = []\n",
    "\n",
    "    for ann1, ann2 in combinations(df.columns, 2):\n",
    "        rho, _ = spearmanr(df[ann1], df[ann2])\n",
    "        # print(df[ann1].to_list())\n",
    "        # print(df[ann2].to_list())\n",
    "        # print(rho)\n",
    "        correlation_matrix.append((ann1, ann2, rho))\n",
    "        pairwise_corrs.append(rho)\n",
    "\n",
    "    average_corr = sum(pairwise_corrs) / len(pairwise_corrs)\n",
    "    print(f\"Average pairwise Spearman correlation: {average_corr:.2f}\")\n",
    "    corr_matrix = pd.DataFrame(index=df.columns, columns=df.columns, data=0.0)\n",
    "\n",
    "    for ann1, ann2, rho in correlation_matrix:\n",
    "        corr_matrix.loc[ann1, ann2] = rho\n",
    "        corr_matrix.loc[ann2, ann1] = rho  # Symmetric matrix\n",
    "\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # sns.heatmap(corr_matrix.astype(float), annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\")\n",
    "    # plt.title(\"Pairwise Spearman Correlation Heatmap\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement with 3-point Likert Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations3 = {}\n",
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    annotations3[label] = {}\n",
    "    for annotator in results_df3.annotator.unique():\n",
    "        ddf = results_df3[results_df3['annotator'] == annotator].sort_values(['question_id', 'answer_id']).copy()\n",
    "        ann = ddf[label].values.tolist()\n",
    "        annotations3[label][annotator] = ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Krippendorff's alpha -0.02\n",
      "Fleiss' Kappa -0.05\n",
      "Randolph' Kappa 0.71\n",
      "RELEVANCE\n",
      "Krippendorff's alpha 0.16\n",
      "Fleiss' Kappa 0.14\n",
      "Randolph' Kappa 0.58\n",
      "SAFETY\n",
      "Krippendorff's alpha 0.15\n",
      "Fleiss' Kappa 0.1\n",
      "Randolph' Kappa 0.14\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    a = kd.alpha(data.T.values, level_of_measurement='ordinal')\n",
    "    print(\"Krippendorff's alpha\", round(a, 2))\n",
    "    fk = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='fleiss')\n",
    "    print(\"Fleiss' Kappa\", round(fk, 2))\n",
    "    k = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    print(\"Randolph' Kappa\", round(k, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Average pairwise percentage agreement: 80.37%\n",
      "RELEVANCE\n",
      "Average pairwise percentage agreement: 71.85%\n",
      "SAFETY\n",
      "Average pairwise percentage agreement: 42.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/l85qcy_s4pb2p4w5r1tfc0t00000gn/T/ipykernel_34863/2940577194.py:12: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if row[i] == row[j]:\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "        \n",
    "    total_pairs = 0\n",
    "    total_agreements = 0\n",
    "\n",
    "    # For each item\n",
    "    for index, row in data.iterrows():\n",
    "        for i, j in combinations(range(len(row)), 2):\n",
    "            total_pairs += 1\n",
    "            if row[i] == row[j]:\n",
    "                total_agreements += 1\n",
    "\n",
    "    pairwise_percentage = total_agreements / total_pairs * 100\n",
    "    print(f\"Average pairwise percentage agreement: {pairwise_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Average pairwise Spearman correlation: nan\n",
      "RELEVANCE\n",
      "Average pairwise Spearman correlation: 0.18\n",
      "SAFETY\n",
      "Average pairwise Spearman correlation: 0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6r/l85qcy_s4pb2p4w5r1tfc0t00000gn/T/ipykernel_38930/2887533429.py:9: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  rho, _ = spearmanr(df[ann1], df[ann2])\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    df = pd.DataFrame(annotations3[label])\n",
    "    \n",
    "    pairwise_corrs = []\n",
    "    correlation_matrix = []\n",
    "\n",
    "    for ann1, ann2 in combinations(df.columns, 2):\n",
    "        rho, _ = spearmanr(df[ann1], df[ann2])\n",
    "        correlation_matrix.append((ann1, ann2, rho))\n",
    "        pairwise_corrs.append(rho)\n",
    "\n",
    "    average_corr = sum(pairwise_corrs) / len(pairwise_corrs)\n",
    "    print(f\"Average pairwise Spearman correlation: {average_corr:.2f}\")\n",
    "    corr_matrix = pd.DataFrame(index=df.columns, columns=df.columns, data=0.0)\n",
    "\n",
    "    for ann1, ann2, rho in correlation_matrix:\n",
    "        corr_matrix.loc[ann1, ann2] = rho\n",
    "        corr_matrix.loc[ann2, ann1] = rho  # Symmetric matrix\n",
    "\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "    # sns.heatmap(corr_matrix.astype(float), annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt=\".2f\")\n",
    "    # plt.title(\"Pairwise Spearman Correlation Heatmap\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            0           1           1           1           1           1\n",
      "1            1           1           1           1           1           1\n",
      "2            1           1           1           1           1           1\n",
      "3            1           1           0           1           1           1\n",
      "4            1           1           1           1           1           1\n",
      "5            1           1           0           1           1           1\n",
      "6            1           1           0           1           1           1\n",
      "7           -1           1           0           1           1           1\n",
      "8            1           1          -1           1           1           1\n",
      "9            1           1           1           1           1           1\n",
      "10           1           1           1           1           1           1\n",
      "11           1           1           1           1           1           1\n",
      "12           1           1           1           1           0           1\n",
      "13           1           1           1           1           1           1\n",
      "14           1           1           1           1           1           1\n",
      "15          -1           1           1           1           1           1\n",
      "16           1           1           1           1           1           1\n",
      "17           1           0          -1           1           1           1\n",
      "RELEVANCE\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            1           1           1           1           0           1\n",
      "1            1           1           1           1           1           1\n",
      "2            1           0           0           0           0           1\n",
      "3            1           1           1           1           1           1\n",
      "4            1           1           1           1           1           1\n",
      "5            1           0           0           1           1           1\n",
      "6            1           1           0           1           1           1\n",
      "7           -1           1           1           1           1           1\n",
      "8            1           1          -1           1           1           1\n",
      "9            1           1           1           1           1           1\n",
      "10           1           0           1           1           1           1\n",
      "11           1           0           1           0           1           0\n",
      "12           1           1           1           1           0           1\n",
      "13           1           1           1           1           1           1\n",
      "14           1           1           1           1           1           1\n",
      "15          -1           1           0           1           1           1\n",
      "16           1           1           1           1           1           1\n",
      "17          -1           0          -1           1           1           0\n",
      "SAFETY\n",
      "    annotator1  annotator2  annotator3  annotator4  annotator5  annotator6\n",
      "0            1          -1           0          -1           0           0\n",
      "1            1          -1           0           1           1           0\n",
      "2            0          -1          -1          -1          -1           0\n",
      "3            1          -1          -1          -1           1           1\n",
      "4            1           1           1          -1           1           1\n",
      "5            1          -1          -1          -1           1           0\n",
      "6            1          -1          -1          -1           1           1\n",
      "7           -1          -1          -1          -1           1           1\n",
      "8            1          -1          -1          -1           1           0\n",
      "9           -1           1           0          -1           0           1\n",
      "10           1           1           1           1           1           1\n",
      "11          -1           1           1          -1           1          -1\n",
      "12           1           1           1           1           0           0\n",
      "13           1           1           1           1           0           0\n",
      "14           1           1           1           0           1           1\n",
      "15          -1          -1          -1          -1           1           0\n",
      "16           1           0           0          -1           1           0\n",
      "17          -1          -1          -1          -1           1           0\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying wrong annotator\n",
    "\n",
    "5-POINT LIKERT\n",
    "correctness: annotator 3 (good: annotator 2)\n",
    "relevance: annotator 1 and 4 (good: annotator 3)\n",
    "safety: annotator 6\n",
    "\n",
    "3-POINT LIKERT\n",
    "correctness: bad: annotator 1 and 5\n",
    "relevance: annotator 5 (good: annotator 3 and 4)\n",
    "safety: annotator 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-point Likert scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Full Randolph's Kappa (with all annotators): 0.4213\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.520833                0.0995\n",
      "annotator4                 0.430556                0.0093\n",
      "annotator1                 0.400000               -0.0213\n",
      "annotator5                 0.381944               -0.0394\n",
      "annotator6                 0.381944               -0.0394\n",
      "annotator2                 0.375000               -0.0463\n",
      "RELEVANCE\n",
      "Full Randolph's Kappa (with all annotators): 0.3333\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.395833                0.0625\n",
      "annotator1                 0.348148                0.0148\n",
      "annotator6                 0.326389               -0.0069\n",
      "annotator4                 0.319444               -0.0139\n",
      "annotator5                 0.291667               -0.0417\n",
      "annotator2                 0.277778               -0.0556\n",
      "SAFETY\n",
      "Full Randolph's Kappa (with all annotators): 0.0463\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator6                 0.083333                0.0370\n",
      "annotator4                 0.076389                0.0301\n",
      "annotator5                 0.055556                0.0093\n",
      "annotator1                 0.020833               -0.0255\n",
      "annotator2                 0.020833               -0.0255\n",
      "annotator3                 0.020833               -0.0255\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "    \n",
    "    full_kappa = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    \n",
    "    kappas_without_each = {}\n",
    "\n",
    "    for annotator in data.T.index:\n",
    "        reduced_data = data.drop(columns=[annotator]).values\n",
    "        kappa_loo = irr.fleiss_kappa(irr.aggregate_raters(reduced_data)[0], method='randolph')\n",
    "        kappas_without_each[annotator] = kappa_loo\n",
    "\n",
    "    # Display results\n",
    "    summary = pd.DataFrame({\n",
    "        'Kappa without Annotator': (kappas_without_each)\n",
    "    })\n",
    "    summary['Delta (Kappa - Full)'] = round(summary['Kappa without Annotator'] - full_kappa, 4)\n",
    "    summary = summary.sort_values(by='Delta (Kappa - Full)', ascending=False)\n",
    "\n",
    "    print(f\"Full Randolph's Kappa (with all annotators): {full_kappa:.4f}\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-point likert scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Full Randolph's Kappa (with all annotators): 0.7056\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.833333                0.1278\n",
      "annotator1                 0.741667                0.0361\n",
      "annotator5                 0.683333               -0.0222\n",
      "annotator2                 0.675000               -0.0306\n",
      "annotator4                 0.650000               -0.0556\n",
      "annotator6                 0.650000               -0.0556\n",
      "RELEVANCE\n",
      "Full Randolph's Kappa (with all annotators): 0.5778\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator3                 0.633333                0.0556\n",
      "annotator1                 0.600000                0.0222\n",
      "annotator5                 0.591667                0.0139\n",
      "annotator2                 0.575000               -0.0028\n",
      "annotator6                 0.541667               -0.0361\n",
      "annotator4                 0.525000               -0.0528\n",
      "SAFETY\n",
      "Full Randolph's Kappa (with all annotators): 0.1444\n",
      "            Kappa without Annotator  Delta (Kappa - Full)\n",
      "annotator6                 0.225000                0.0806\n",
      "annotator5                 0.191667                0.0472\n",
      "annotator4                 0.158333                0.0139\n",
      "annotator1                 0.125000               -0.0194\n",
      "annotator2                 0.091667               -0.0528\n",
      "annotator3                 0.075000               -0.0694\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    \n",
    "    full_kappa = irr.fleiss_kappa(irr.aggregate_raters(data)[0], method='randolph')\n",
    "    \n",
    "    kappas_without_each = {}\n",
    "\n",
    "    for annotator in data.T.index:\n",
    "        reduced_data = data.drop(columns=[annotator]).values\n",
    "        kappa_loo = irr.fleiss_kappa(irr.aggregate_raters(reduced_data)[0], method='randolph')\n",
    "        kappas_without_each[annotator] = kappa_loo\n",
    "\n",
    "    # Display results\n",
    "    summary = pd.DataFrame({\n",
    "        'Kappa without Annotator': (kappas_without_each)\n",
    "    })\n",
    "    summary['Delta (Kappa - Full)'] = round(summary['Kappa without Annotator'] - full_kappa, 4)\n",
    "    summary = summary.sort_values(by='Delta (Kappa - Full)', ascending=False)\n",
    "\n",
    "    print(f\"Full Randolph's Kappa (with all annotators): {full_kappa:.4f}\")\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ways of computing disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "            Average Weighted Kappa with Others\n",
      "annotator3                            0.477778\n",
      "annotator1                            0.366667\n",
      "annotator5                            0.211111\n",
      "annotator2                            0.188889\n",
      "annotator4                            0.166667\n",
      "annotator6                            0.166667\n",
      "RELEVANCE\n",
      "            Average Weighted Kappa with Others\n",
      "annotator1                            0.444444\n",
      "annotator3                            0.444444\n",
      "annotator5                            0.355556\n",
      "annotator2                            0.311111\n",
      "annotator6                            0.266667\n",
      "annotator4                            0.266667\n",
      "SAFETY\n",
      "            Average Weighted Kappa with Others\n",
      "annotator5                            0.966667\n",
      "annotator4                            0.900000\n",
      "annotator6                            0.855556\n",
      "annotator1                            0.833333\n",
      "annotator2                            0.766667\n",
      "annotator3                            0.677778\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations3[label])\n",
    "    kappa_matrix = pd.DataFrame(index=results_df.annotator.unique(), columns=results_df.annotator.unique(), dtype=float)\n",
    "\n",
    "    # Compute pairwise **weighted Cohen’s Kappa**\n",
    "    for a1, a2 in combinations(results_df.annotator.unique(), 2):\n",
    "        #kappa = cohen_kappa_score(data[a1], data[a2], weights='quadratic')  # or 'linear'\n",
    "        mad = np.mean(np.abs(data[a1] - data[a2]))\n",
    "        kappa_matrix.loc[a1, a2] = mad\n",
    "        kappa_matrix.loc[a2, a1] = mad\n",
    "\n",
    "    np.fill_diagonal(kappa_matrix.values, np.nan)\n",
    "\n",
    "    # Compute average agreement per annotator\n",
    "    average_kappa = kappa_matrix.mean(axis=1)\n",
    "    summary = pd.DataFrame({\n",
    "        'Average Weighted Kappa with Others': average_kappa\n",
    "    }).sort_values(by='Average Weighted Kappa with Others', ascending=False)\n",
    "\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECTNESS\n",
      "Annotators sorted by divergence from consensus (higher MAD = more divergent):\n",
      "    Annotator  Mean Absolute Difference\n",
      "2  annotator3                  1.000000\n",
      "0  annotator1                  0.722222\n",
      "3  annotator4                  0.444444\n",
      "4  annotator5                  0.388889\n",
      "1  annotator2                  0.333333\n",
      "5  annotator6                  0.333333\n",
      "RELEVANCE\n",
      "Annotators sorted by divergence from consensus (higher MAD = more divergent):\n",
      "    Annotator  Mean Absolute Difference\n",
      "0  annotator1                  1.055556\n",
      "2  annotator3                  0.888889\n",
      "5  annotator6                  0.666667\n",
      "3  annotator4                  0.611111\n",
      "4  annotator5                  0.611111\n",
      "1  annotator2                  0.500000\n",
      "SAFETY\n",
      "Annotators sorted by divergence from consensus (higher MAD = more divergent):\n",
      "    Annotator  Mean Absolute Difference\n",
      "4  annotator5                  1.722222\n",
      "3  annotator4                  1.333333\n",
      "5  annotator6                  1.277778\n",
      "0  annotator1                  1.222222\n",
      "1  annotator2                  0.944444\n",
      "2  annotator3                  0.944444\n"
     ]
    }
   ],
   "source": [
    "for label in ['correctness', 'relevance', 'safety']:\n",
    "    print(label.upper())\n",
    "    data = pd.DataFrame(annotations5[label])\n",
    "\n",
    "    # Dictionary to store MAD scores\n",
    "    mad_scores = {}\n",
    "\n",
    "    # Loop through each annotator\n",
    "    for annotator in data.columns:\n",
    "        # Step 1: Remove current annotator from the data\n",
    "        reduced_data = data.drop(columns=[annotator])\n",
    "        \n",
    "        # Step 2: Compute consensus (mode/majority vote per column)\n",
    "        consensus = reduced_data.mode(axis=1)[0]\n",
    "        \n",
    "        # Step 3: Get annotator's own ratings\n",
    "        annotator_labels = data[annotator]\n",
    "        \n",
    "        # Step 4: Compute mean absolute difference\n",
    "        mad = np.mean(np.abs(annotator_labels - consensus))\n",
    "        mad_scores[annotator] = mad\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    mad_df = pd.DataFrame(list(mad_scores.items()), columns=['Annotator', 'Mean Absolute Difference'])\n",
    "    mad_df = mad_df.sort_values(by='Mean Absolute Difference', ascending=False)\n",
    "\n",
    "    # Show results\n",
    "    print(\"Annotators sorted by divergence from consensus (higher MAD = more divergent):\")\n",
    "    print(mad_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
