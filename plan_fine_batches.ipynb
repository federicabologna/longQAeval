{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats import inter_rater as irr\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import krippendorff as kd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File locations\n",
    "dir = os.getcwd()\n",
    "output_dir = os.path.join(dir, 'output')\n",
    "fig_dir = os.path.join(dir, 'figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO ASSEMBLE BATCHES\n",
    "# for n in range(1,7):\n",
    "#     if n not in [1,2,6]:\n",
    "#         results = []\n",
    "#         with open(os.path.join(output_dir, 'coarse', 'batches_1-9', f\"annotator{n}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "#             for line in jsonl_file:\n",
    "#                 d = json.loads(line)\n",
    "#                 d['annotator'] = f\"annotator{n}\"\n",
    "#                 results.append(d)\n",
    "        \n",
    "#         output_file = f\"annotator{n}.jsonl\"\n",
    "#         with open(os.path.join('output', 'coarse', output_file), 'w', encoding='utf-8') as f:\n",
    "#             for doc in results:\n",
    "#                 f.write(json.dumps(doc, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for n in range(1,7):\n",
    "    with open(os.path.join(output_dir, 'coarse', 'batches_1-9', f\"annotator{n}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            d = json.loads(line)\n",
    "            if d['rated'] == 'Yes':\n",
    "                d['annotator'] = f\"annotator{n}\"\n",
    "                results.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD BATCH 9 for annotator3\n",
    "with open(os.path.join(output_dir, 'coarse', 'afterapril9', f\"annotator3.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        d = json.loads(line)\n",
    "        if d['rated'] == 'Yes' and (d['batch_id'] == 'batch_7' or d['batch_id'] == 'batch_8' or d['batch_id'] == 'batch_9'):\n",
    "            d['annotator'] = f\"annotator3\"\n",
    "            results.append(d)\n",
    "\n",
    "with open(os.path.join(output_dir, 'coarse', 'afterapril9', f\"annotator6.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "    for line in jsonl_file:\n",
    "        d = json.loads(line)\n",
    "        if d['rated'] == 'Yes' and (d['batch_id'] == 'batch_8' or d['batch_id'] == 'batch_9'):\n",
    "            d['annotator'] = f\"annotator6\"\n",
    "            results.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_type</th>\n",
       "      <th>annotation_type</th>\n",
       "      <th>rated</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>confidence</th>\n",
       "      <th>correctness</th>\n",
       "      <th>relevance</th>\n",
       "      <th>safety</th>\n",
       "      <th>time</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67d43fe8ccebca25cea425dc</td>\n",
       "      <td>question_180</td>\n",
       "      <td>Whats Keratosis Pilaris</td>\n",
       "      <td>gpt4_43</td>\n",
       "      <td>Keratosis Pilaris is a common skin condition c...</td>\n",
       "      <td>gpt4</td>\n",
       "      <td>coarse</td>\n",
       "      <td>Yes</td>\n",
       "      <td>batch_1</td>\n",
       "      <td>Fairly confident</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Partially Disagree</td>\n",
       "      <td>Partially Disagree</td>\n",
       "      <td>25.293506</td>\n",
       "      <td>annotator1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id   question_id                 question answer_id  \\\n",
       "0  67d43fe8ccebca25cea425dc  question_180  Whats Keratosis Pilaris   gpt4_43   \n",
       "\n",
       "                                              answer answer_type  \\\n",
       "0  Keratosis Pilaris is a common skin condition c...        gpt4   \n",
       "\n",
       "  annotation_type rated batch_id        confidence correctness  \\\n",
       "0          coarse   Yes  batch_1  Fairly confident     Neutral   \n",
       "\n",
       "            relevance              safety       time   annotator  \n",
       "0  Partially Disagree  Partially Disagree  25.293506  annotator1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many questions and QA pairs have they already annotated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotator1 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator2 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator3 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator4 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator5 annotated QA pairs: 81 annotated Qs 27\n",
      "annotator6 annotated QA pairs: 81 annotated Qs 27\n"
     ]
    }
   ],
   "source": [
    "annotators = {}\n",
    "for n in range(1,7):\n",
    "    annotator = f'annotator{n}'\n",
    "    annotated_qs = results_df[results_df['annotator'] == annotator]\n",
    "    print(f'annotator{n}', 'annotated QA pairs:', len(annotated_qs), 'annotated Qs', len(annotated_qs.question_id.unique()))\n",
    "    annotators[annotator] = annotated_qs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's the overlap between annotators?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp1 = np.intersect1d(annotators['annotator1'].question_id, annotators['annotator2'].question_id)\n",
    "len(np.intersect1d(annotators['annotator6'].question_id, grp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp2 = np.intersect1d(annotators['annotator3'].question_id, annotators['annotator4'].question_id)\n",
    "len(np.intersect1d(annotators['annotator5'].question_id, grp2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question_ids in coarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine question_ids for each annotator\n",
    "groups = {}\n",
    "for n in range(1,7):\n",
    "    with open(os.path.join(output_dir, 'coarse', 'batches_1-9', f\"annotator{n}.jsonl\"), 'r', encoding='utf-8') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            d = json.loads(line)\n",
    "            if f\"annotator{n}\" not in groups.keys():\n",
    "                groups[f\"annotator{n}\"] = []\n",
    "            groups[f\"annotator{n}\"].append(d['question_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find intersection for group 1\n",
    "grp1 = np.intersect1d(set(groups['annotator1']), set(groups['annotator2']))[0]\n",
    "coarse_questions_grp1 = list(np.intersect1d(set(groups['annotator6']), grp1)[0])\n",
    "len(set(coarse_questions_grp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find set for group 1\n",
    "coarse_set_grp1 = set(groups['annotator1'] + groups['annotator2'] + groups['annotator6'])\n",
    "len(coarse_set_grp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype='<U12')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that they are the same\n",
    "np.setdiff1d(list(coarse_set_grp1), coarse_questions_grp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find intersection for group 2\n",
    "grp2 = np.intersect1d(set(groups['annotator3']), set(groups['annotator4']))[0]\n",
    "coarse_questions_grp2 = list(np.intersect1d(set(groups['annotator5']), grp2)[0])\n",
    "len(set(coarse_questions_grp2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find set for group 2\n",
    "coarse_set_grp2 = set(groups['annotator3'] + groups['annotator4'] + groups['annotator5'])\n",
    "len(coarse_set_grp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype='<U12')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that they are the same\n",
    "np.setdiff1d(list(coarse_set_grp2), coarse_questions_grp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype='<U12')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that groups do not share question_ids\n",
    "np.intersect1d(coarse_questions_grp1, coarse_questions_grp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What questions in Fine Part 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_part_2 = {}\n",
    "for n in range(1,7):\n",
    "    annotator = f'annotator{n}'\n",
    "    fine_part_2[annotator] = []\n",
    "    if n in [1,2,6]:\n",
    "        for q_id in coarse_questions_grp1: # for all questions in coarse\n",
    "            if q_id not in results_df[results_df['annotator'] == annotator].question_id.unique(): # if question not annotated in coarse part 1\n",
    "                fine_part_2[annotator].append(q_id) # append to fin part 2\n",
    "    else:\n",
    "        for q_id in coarse_questions_grp2:\n",
    "            if q_id not in results_df[results_df['annotator'] == annotator].question_id.unique():\n",
    "                fine_part_2[annotator].append(q_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join('fine_part_2.json'), 'w') as json_file:\n",
    "#     json.dump(fine_part_2, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "[]\n",
      "50\n",
      "[]\n",
      "50\n",
      "[]\n",
      "50\n",
      "[]\n",
      "50\n",
      "[]\n",
      "50\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,7):\n",
    "    annotator = f'annotator{n}'\n",
    "    # add fine part 2 and coarse part 1 question_ids to double check\n",
    "    double_check = fine_part_2[annotator].copy() + list(results_df[results_df['annotator'] == annotator].question_id.unique()) \n",
    "    print(len(double_check))\n",
    "    if n in [1,2,6]:\n",
    "        #check that the coarse fine part 2 and coarse part 1 question_ids are the same as the total set of questions\n",
    "        print(np.setdiff1d(list(coarse_set_grp1), double_check)) \n",
    "    else:\n",
    "        print(np.setdiff1d(list(coarse_set_grp2), double_check)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What questions in Fine Part 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_part_1 = {}\n",
    "for n in range(1,7):\n",
    "    annotator = f'annotator{n}'\n",
    "    fine_part_1[annotator] = []\n",
    "    if n in [1,2,6]:\n",
    "        for q_id in results_df[results_df['annotator'] == annotator].question_id.unique(): # if question annotated in coarse part 1\n",
    "            fine_part_1[annotator].append(q_id) # append to fine part 1\n",
    "    else:\n",
    "        for q_id in results_df[results_df['annotator'] == annotator].question_id.unique():\n",
    "            fine_part_1[annotator].append(q_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('fine_part_1.json'), 'w') as json_file:\n",
    "    json.dump(fine_part_1, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "50\n",
      "50\n",
      "[]\n",
      "[]\n",
      "50\n",
      "50\n",
      "[]\n",
      "[]\n",
      "50\n",
      "50\n",
      "[]\n",
      "[]\n",
      "50\n",
      "50\n",
      "[]\n",
      "[]\n",
      "50\n",
      "50\n",
      "[]\n",
      "[]\n",
      "50\n",
      "50\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,7):\n",
    "    annotator = f'annotator{n}'\n",
    "    print(np.intersect1d(fine_part_1[annotator], fine_part_2[annotator])) # check that there are is no overlap between fine part 1 and fine part 2\n",
    "    double_check = fine_part_1[annotator].copy() + fine_part_2[annotator].copy()\n",
    "    print(len(double_check))\n",
    "    print(len(set(double_check)))\n",
    "    if n in [1,2,6]:\n",
    "        #check that the coarse fine part 2 and coarse part 1 question_ids are the same as the total set of questions\n",
    "        print(np.setdiff1d(list(coarse_set_grp1), double_check)) \n",
    "    else:\n",
    "        print(np.setdiff1d(list(coarse_set_grp2), double_check)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
